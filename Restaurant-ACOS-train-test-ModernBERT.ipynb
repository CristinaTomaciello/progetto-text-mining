{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7266c47e",
   "metadata": {},
   "source": [
    "# Estrazione delle quadruple (aspect-opinion-category-sentiment) con ModernBERT su Restaurant-ACOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a40e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate.\n"
     ]
    }
   ],
   "source": [
    "# Import delle librerie necessarie\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "import pickle\n",
    "\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.amp import autocast, GradScaler # Per Mixed Precision\n",
    "\n",
    "print(\"Librerie caricate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70bed1",
   "metadata": {},
   "source": [
    "### Impostazioni per la riproducibilit√† "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68aa33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seeds impostati su 42.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Imposto i seed per la riproducibilit√†.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        # Imposto anche i seed per la GPU, se disponibile\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# Esegui l'impostazione del seed\n",
    "set_seed(42) \n",
    "print(\"Random seeds impostati su 42.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb63eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristinatomaciello2001\u001b[0m (\u001b[33mcristinatextmining\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cristinatomaciello/Desktop/UniversitaÃÄ/2anno/1semstre/big data/progetto-text-mining/wandb/run-20260219_214947-1zpqmbz5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/1zpqmbz5' target=\"_blank\">run_answerdotai/ModernBERT-base_Restaurant-ACOS</a></strong> to <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/1zpqmbz5' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/1zpqmbz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B inizializzato per il progetto: BigData-TextMining-ACOS\n",
      "Nome della Run attuale: run_answerdotai/ModernBERT-base_Restaurant-ACOS\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_ENTITY = \"cristinatextmining\"\n",
    "\n",
    "# 1. Definizione degli Hyperparameters\n",
    "config = {\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 16,\n",
    "    \"model_name\": \"answerdotai/ModernBERT-base\",\n",
    "    \"dataset\": \"Restaurant-ACOS\",  \n",
    "    \"seed\": 42,\n",
    "    'patience': 2  # Per Early Stopping\n",
    "}\n",
    "\n",
    "# 2. Inizializzazione del Run\n",
    "wandb.init(\n",
    "    project=\"BigData-TextMining-ACOS\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    config=config,\n",
    "    name=f\"run_{config['model_name']}_{config['dataset']}\"\n",
    ")\n",
    "\n",
    "print(f\"W&B inizializzato per il progetto: {wandb.run.project}\")\n",
    "print(f\"Nome della Run attuale: {wandb.run.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84319964",
   "metadata": {},
   "source": [
    "## PyTorch Dataset & DataLoader Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114bba6",
   "metadata": {},
   "source": [
    "### Creazione di PyTorch Dataset e DataLoader\n",
    "In questa fase, trasformiamo i nostri DataFrame Pandas (strutture dati tabellari) in oggetti Dataset e DataLoader di PyTorch. Questo passaggio √® il \"ponte\" necessario per alimentare il modello ModernBERT durante l'addestramento.\n",
    "\n",
    "#### Obiettivi di questa sezione:\n",
    "\n",
    "  1. Standardizzazione dei Dati (ACOSDataset):\n",
    "\n",
    "       * I modelli basati su Transformer non possono leggere direttamente i DataFrame. La classe ACOSDataset estrae le liste di input_ids, attention_mask e labels e le converte in Tensori PyTorch (torch.tensor).\n",
    "\n",
    "       * Viene utilizzato il tipo di dato torch.long, richiesto dai layer di embedding e dalle funzioni di calcolo della Loss per task di classificazione.\n",
    "\n",
    "  2. Gestione del Caricamento (DataLoader):\n",
    "\n",
    "      * Batching: Invece di caricare l'intero dataset in memoria (rischioso per la GPU), i dati vengono divisi in piccoli blocchi chiamati Batch (nel nostro caso di dimensione 16).\n",
    "\n",
    "      * Shuffling (Solo Training): Utilizziamo shuffle=True nel train_loader per rimescolare l'ordine delle frasi a ogni epoca. Questo impedisce al modello di imparare l'ordine sequenziale dei dati, costringendolo invece a focalizzarsi sui pattern linguistici reali.\n",
    "\n",
    "      * Efficienza: I DataLoader gestiscono il caricamento dei dati in parallelo, ottimizzando i tempi di addestramento sulla GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7f7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Caricamento dei dataset pre-processati...\n",
      "Dataset e DataLoaders creati con successo!\n",
      "Esempi nel set di Training RESTAURANT: 1530\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. CARICAMENTO DEI DATASET SALVATI  ---\n",
    "cartella_dati = \"data_allineati\"\n",
    "\n",
    "print(\"üìÇ Caricamento dei dataset pre-processati...\")\n",
    "# Carichiamo i Ristoranti\n",
    "df_train_align_rest = pd.read_pickle(os.path.join(cartella_dati, \"train_rest_aligned.pkl\"))\n",
    "df_dev_align_rest = pd.read_pickle(os.path.join(cartella_dati, \"dev_rest_aligned.pkl\"))\n",
    "df_test_align_rest = pd.read_pickle(os.path.join(cartella_dati, \"test_rest_aligned.pkl\"))\n",
    "\n",
    "\n",
    "class ACOSDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Estraiamo le colonne che abbiamo generato nella fase di allineamento\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.labels = df['labels'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convertiamo le liste in Tensori di PyTorch (LongTensor per ID e Label)\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- CREAZIONE DELLE ISTANZE ---\n",
    "\n",
    "# Creiamo i dataset per il dominio restaruant\n",
    "train_dataset_rest = ACOSDataset(df_train_align_rest)\n",
    "dev_dataset_rest = ACOSDataset(df_dev_align_rest)\n",
    "test_dataset_rest = ACOSDataset(df_test_align_rest)\n",
    "\n",
    "# --- CONFIGURAZIONE DATALOADERS ---\n",
    "\n",
    "BATCH_SIZE = 16 # Numero di frasi analizzate contemporaneamente\n",
    "\n",
    "train_loader_rest = DataLoader(train_dataset_rest, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader_rest = DataLoader(dev_dataset_rest, batch_size=BATCH_SIZE)\n",
    "test_loader_rest = DataLoader(test_dataset_rest, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Dataset e DataLoaders creati con successo!\")\n",
    "print(f\"Esempi nel set di Training RESTAURANT: {len(train_dataset_rest)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b70053",
   "metadata": {},
   "source": [
    "### Definizione e l'Inizializzazione del Modello di Token Classification.\n",
    "\n",
    "1. Caricare il \"Cervello\" (ModernBERT Pre-trained)\n",
    "Dobbiamo scaricare il modello ModernBERT-base dal repository di Hugging Face. In questa fase, il modello sa gi√† \"leggere\" e \"capire\" la lingua inglese perch√© √® stato addestrato su miliardi di testi, ma non sa ancora nulla del tuo task specifico (ACOS). √à come un laureato in lingue che per√≤ non ha mai lavorato in un ristorante o in un negozio di computer.\n",
    "\n",
    "2. Aggiungere la \"Testa\" di Classificazione\n",
    "ModernBERT normalmente restituisce dei vettori numerici (embedding) per ogni parola. Noi dobbiamo aggiungere sopra questi vettori uno strato finale chiamato Linear Layer (o testa di classificazione).\n",
    "\n",
    "   * Questo strato prender√† l'output di ModernBERT e lo \"schiaccer√†\" su 5 classi possibili: 0 (O), 1 (B-ASP), 2 (I-ASP), 3 (B-OPI), 4 (I-OPI).\n",
    "\n",
    "   * Il modello dovr√† imparare a mappare ogni pezzetto di frase a una di queste cinque etichette.\n",
    "\n",
    "3. Configurare la Strategia di Apprendimento (Optimizer & Loss)\n",
    "Dobbiamo dare al modello gli strumenti per imparare dai suoi errori:\n",
    "\n",
    "  * Loss Function (Funzione di Perdita): Useremo la CrossEntropyLoss. √à il \"voto\" che diamo al modello. Se il modello dice che \"pizza\" √® un'opinione (B-OPI) ma il tuo dataset dice che √® un aspetto (B-ASP), la Loss sar√† alta. Il modello cercher√† di abbassarla il pi√π possibile.\n",
    "\n",
    "   * Optimizer (Ottimizzatore): Di solito si usa AdamW. √à l'algoritmo che decide \"come\" e \"quanto\" cambiare i pesi interni del modello per correggere gli errori.\n",
    "\n",
    "   * Learning Rate: La velocit√† con cui il modello impara. Se √® troppo alta, il modello √® \"frettoloso\" e sbaglia; se √® troppo bassa, non imparer√† mai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "404429b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU Trovata: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Scaricamento e configurazione di ModernBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52422e58cfaa406aa0e2f77900cc5060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mModernBertForTokenClassification LOAD REPORT\u001b[0m from: answerdotai/ModernBERT-base\n",
      "Key               | Status     | \n",
      "------------------+------------+-\n",
      "decoder.bias      | UNEXPECTED | \n",
      "classifier.weight | MISSING    | \n",
      "classifier.bias   | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODELLO PRONTO PER IL TRAINING\n",
      "==================================================\n",
      "Architettura: ModernBERT-base\n",
      "Task: Token Classification (Estrazione Aspetti & Opinioni)\n",
      "Numero di Classi: 5\n",
      "Optimizer: AdamW 8-bit (lr=5e-5)\n",
      "Loss Function: CrossEntropyLoss\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. CONFIGURAZIONE DEL DEVICE ---\n",
    "# Se hai una GPU NVIDIA, user√† 'cuda'. Se hai un Mac M1/M2, user√† 'mps'. Altrimenti 'cpu'.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\" GPU Trovata: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\" Acceleratore Apple Metal (MPS) Trovato\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\" Nessuna GPU trovata. L'addestramento sar√† lento.\")\n",
    "\n",
    "# --- 2. CARICAMENTO DI MODERNBERT (IL \"CERVELLO\") + TESTA DI CLASSIFICAZIONE ---\n",
    "# Definiamo le 5 etichette: 0=O, 1=B-ASP, 2=I-ASP, 3=B-OPI, 4=I-OPI\n",
    "NUM_LABELS = 5 \n",
    "\n",
    "print(\"Scaricamento e configurazione di ModernBERT...\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "# Spostiamo il modello sul dispositivo di calcolo (GPU/MPS/CPU)\n",
    "model.to(device)\n",
    "\n",
    "# --- 3. CONFIGURAZIONE DELL'OTTIMIZZATORE E DELLA LOSS ---\n",
    "\n",
    "\n",
    "\n",
    "# A. Optimizer (AdamW 8-bit)\n",
    "# Usiamo il Learning Rate standard di 5e-5 come definito nei parametri sperimentali \n",
    "# e la versione a 8-bit per non saturare la memoria\n",
    "optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=5e-5)\n",
    "\n",
    "# B. Loss Function (CrossEntropyLoss)\n",
    "# La funzione che calcola l'errore tra la predizione del modello e le label reali.\n",
    "# Nota: 'ignore_index=-100' √® lo standard di PyTorch per ignorare i token di padding nel calcolo dell'errore.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELLO PRONTO PER IL TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Architettura: ModernBERT-base\")\n",
    "print(f\"Task: Token Classification (Estrazione Aspetti & Opinioni)\")\n",
    "print(f\"Numero di Classi: {NUM_LABELS}\")\n",
    "print(f\"Optimizer: AdamW 8-bit (lr=5e-5)\")\n",
    "print(f\"Loss Function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e772824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training su RESTAURANT: 10 epoche | Device: cuda\n",
      "üì¶ Accumulo Gradienti ogni 4 step | FP16 Attivato\n",
      "\n",
      "--- Epoca 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.87it/s, loss=0.0938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.2205 | üîç Valid Loss: 0.0974\n",
      "üíæ Miglior modello trovato (Loss: 0.0974)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06057844de074a8280bb3b7d4cb60241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.90it/s, loss=0.0757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0855 | üîç Valid Loss: 0.0581\n",
      "üíæ Miglior modello trovato (Loss: 0.0581)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a5d3a9aeab4948851a8cbd726528f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.98it/s, loss=0.0501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0536 | üîç Valid Loss: 0.0414\n",
      "üíæ Miglior modello trovato (Loss: 0.0414)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bac6ed5cf02478099dc76b26166517d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.83it/s, loss=0.0604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0363 | üîç Valid Loss: 0.0410\n",
      "üíæ Miglior modello trovato (Loss: 0.0410)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d3cf70952c4d999ca6a79d7ac1e52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  5.00it/s, loss=0.0217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0249 | üîç Valid Loss: 0.0394\n",
      "üíæ Miglior modello trovato (Loss: 0.0394)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8b4760b16a4703b374654ca3aed238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.87it/s, loss=0.0219] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0160 | üîç Valid Loss: 0.0426\n",
      "‚ö†Ô∏è Nessun miglioramento. Patience: 1/2\n",
      "\n",
      "--- Epoca 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:19<00:00,  4.86it/s, loss=0.00836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.0096 | üîç Valid Loss: 0.0464\n",
      "‚ö†Ô∏è Nessun miglioramento. Patience: 2/2\n",
      "\n",
      "üõë EARLY STOPPING ATTIVATO! Interruzione all'epoca 7.\n",
      "\n",
      "‚úÖ Fine Addestramento.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà</td></tr><tr><td>train_loss_epoch</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>valid_loss_epoch</td><td>‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.00836</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_loss_epoch</td><td>0.00963</td></tr><tr><td>valid_loss_epoch</td><td>0.04638</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_answerdotai/ModernBERT-base_Restaurant-ACOS</strong> at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/zlbxoeep' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/zlbxoeep</a><br> View project at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260219_181332-zlbxoeep/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. CONFIGURAZIONE AVANZATA MEMORIA ---\n",
    "# Gradient Checkpointing: risparmia tantissima VRAM ricalcolando i passaggi intermedi\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Parametri per simulare un batch size maggiore\n",
    "accumulation_steps = config.get('accumulation_steps', 4) \n",
    "patience = config.get('patience', 2)\n",
    "patience_counter = 0\n",
    "\n",
    "optimizer = bnb.optim.AdamW8bit(\n",
    "    model.parameters(), \n",
    "    lr=config['learning_rate']\n",
    ")\n",
    "# Scaler per Mixed Precision (fondamentale per evitare l'OOM)\n",
    "scaler = GradScaler() \n",
    "\n",
    "total_steps = (len(train_loader_rest) // accumulation_steps) * config['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# --- 2. FUNZIONI DI SUPPORTO OTTIMIZZATE ---\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Usiamo autocast anche in valutazione\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device, epoch_idx, scaler, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad() # Reset iniziale\n",
    "    \n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    \n",
    "    for i, batch in enumerate(loop):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # A. Mixed Precision Forward Pass\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps \n",
    "        \n",
    "        # B. Backward Pass con Scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # C. Update Pesi ogni 'accumulation_steps'\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        wandb.log({\"batch_loss\": loss.item() * accumulation_steps})\n",
    "        loop.set_description(f\"Epoca {epoch_idx + 1}\")\n",
    "        loop.set_postfix(loss=loss.item() * accumulation_steps)\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# --- 3. CICLO DI ADDESTRAMENTO ---\n",
    "\n",
    "print(f\"üöÄ Training su RESTAURANT: {config['epochs']} epoche | Device: {device}\")\n",
    "print(f\"üì¶ Accumulo Gradienti ogni {accumulation_steps} step | FP16 Attivato\")\n",
    "\n",
    "best_valid_loss_rest = float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\n--- Epoca {epoch+1}/{config['epochs']} ---\")\n",
    "    \n",
    "    # 1. Training\n",
    "    train_loss_rest = train_epoch(model, train_loader_rest, optimizer, scheduler, device, epoch, scaler, accumulation_steps)\n",
    "    \n",
    "    # 2. Validazione\n",
    "    valid_loss_rest = evaluate_model(model, dev_loader_rest, device)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"üìâ Train Loss: {train_loss_rest:.4f} | üîç Valid Loss: {valid_loss_rest:.4f}\")\n",
    "    \n",
    "    # 3. Log metriche epoca su W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss_epoch\": train_loss_rest,\n",
    "        \"valid_loss_epoch\": valid_loss_rest\n",
    "    })\n",
    "    \n",
    "    # --- LOGICA EARLY STOPPING & CHECKPOINT ---\n",
    "    \n",
    "    # Se il modello migliora (la valid loss scende)\n",
    "    if valid_loss_rest < best_valid_loss_rest:\n",
    "        best_valid_loss_rest = valid_loss_rest\n",
    "        patience_counter = 0  # ### NUOVO: Resettiamo la pazienza ###\n",
    "        \n",
    "        print(f\"üíæ Miglior modello trovato (Loss: {best_valid_loss_rest:.4f})! Salvataggio...\")\n",
    "        \n",
    "\n",
    "        # Creiamo la cartella se non esiste (sicurezza aggiuntiva)\n",
    "        if not os.path.exists(\"./best_model_restaurant\"):\n",
    "            os.makedirs(\"./best_model_restaurant\")\n",
    "            \n",
    "        model.save_pretrained(\"./best_model_restaurant\")\n",
    "        \n",
    "    # Se il modello NON migliora\n",
    "    else:\n",
    "        patience_counter += 1  # ### NUOVO: Incrementiamo il contatore ###\n",
    "        print(f\"‚ö†Ô∏è Nessun miglioramento. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        # Se abbiamo esaurito la pazienza\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nüõë EARLY STOPPING ATTIVATO! Interruzione all'epoca {epoch+1}.\")\n",
    "            break # Esce dal ciclo for\n",
    "\n",
    "print(\"\\n‚úÖ Fine Addestramento.\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6584a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Caricamento del modello migliore...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c7b73e2b8f4b04be69370ef0e66a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Inizio Test sul Dataset Restaurant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test RESTAURANT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:06<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä RISULTATI FINALI (TEST SET - RESTAURANT)\n",
      "==================================================\n",
      "Overall Precision: 0.6832\n",
      "Overall Recall:    0.7110\n",
      "Overall F1-Score:  0.6968\n",
      "Overall Accuracy:  0.9824\n",
      "\n",
      "üîç Dettaglio per Classe (Quello che conta per il paper):\n",
      "--------------------------------------------------\n",
      "üîπ ASP:\n",
      "   Precision: 0.6384\n",
      "   Recall:    0.6447\n",
      "   F1-Score:  0.6416\n",
      "   Support:   608\n",
      "üîπ OPI:\n",
      "   Precision: 0.7229\n",
      "   Recall:    0.7731\n",
      "   F1-Score:  0.7472\n",
      "   Support:   648\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- A. CARICAMENTO DEL \"CAMPIONE\" ---\n",
    "# Carichiamo i pesi migliori salvati durante il training (Epoca 3)\n",
    "print(\"üìÇ Caricamento del modello migliore...\")\n",
    "model_path = \"./best_model_restaurant\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval() # Modalit√† esame (spegne dropout)\n",
    "\n",
    "# --- B. PREPARAZIONE METRICHE ---\n",
    "# Carichiamo la metrica seqeval (standard per NER/ABSA)\n",
    "metric = load(\"seqeval\")\n",
    "\n",
    "# Mappa per decodificare i numeri in etichette\n",
    "# (Assicurati che corrisponda al tuo training!)\n",
    "id2label = {0: 'O', 1: 'B-ASP', 2: 'I-ASP', 3: 'B-OPI', 4: 'I-OPI'}\n",
    "label_list = list(id2label.values())\n",
    "\n",
    "print(\"üöÄ Inizio Test sul Dataset Restaurant...\")\n",
    "\n",
    "# --- C. CICLO DI PREVISIONE ---\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader_rest, desc=\"Test RESTAURANT\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 1. Il modello predice\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # 2. Prendiamo la classe con probabilit√† pi√π alta (argmax)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # 3. Convertiamo i numeri in etichette (pulendo i -100)\n",
    "        # Dobbiamo ignorare i token speciali (-100) usati per il padding/subwords\n",
    "        for i in range(len(labels)):\n",
    "            true_label_row = []\n",
    "            pred_label_row = []\n",
    "            \n",
    "            for j in range(len(labels[i])):\n",
    "                if labels[i][j] != -100: # Ignoriamo i token di padding/speciali\n",
    "                    true_label_row.append(id2label[labels[i][j].item()])\n",
    "                    pred_label_row.append(id2label[preds[i][j].item()])\n",
    "            \n",
    "            true_labels.append(true_label_row)\n",
    "            predictions.append(pred_label_row)\n",
    "\n",
    "# --- D. CALCOLO E STAMPA RISULTATI ---\n",
    "results = metric.compute(predictions=predictions, references=true_labels)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä RISULTATI FINALI (TEST SET - RESTAURANT)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Stampiamo le metriche generali\n",
    "print(f\"Overall Precision: {results['overall_precision']:.4f}\")\n",
    "print(f\"Overall Recall:    {results['overall_recall']:.4f}\")\n",
    "print(f\"Overall F1-Score:  {results['overall_f1']:.4f}\")\n",
    "print(f\"Overall Accuracy:  {results['overall_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nüîç Dettaglio per Classe (Quello che conta per il paper):\")\n",
    "print(\"-\" * 50)\n",
    "# Estraiamo le metriche specifiche per ASP e OPI\n",
    "for key in results.keys():\n",
    "    if key in ['ASP', 'OPI']: # Filtriamo solo le nostre classi di interesse\n",
    "        print(f\"üîπ {key}:\")\n",
    "        print(f\"   Precision: {results[key]['precision']:.4f}\")\n",
    "        print(f\"   Recall:    {results[key]['recall']:.4f}\")\n",
    "        print(f\"   F1-Score:  {results[key]['f1']:.4f}\")\n",
    "        print(f\"   Support:   {results[key]['number']}\") # Quanti ce n'erano davvero\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e4cbc",
   "metadata": {},
   "source": [
    "## Classificatore Category-Sentiment (Extract-Classify-ACOS)\n",
    "\n",
    "Implementiamo il **secondo stadio** dell'architettura proposta nel paper. Dopo aver estratto gli Aspetti e le Opinioni nello Step 1, ora dobbiamo capire a quale Categoria appartengono e qual √® il loro Sentiment.\n",
    "\n",
    "Il codice di preparazione √® diviso in tre componenti fondamentali:\n",
    "\n",
    " 1. Il Dataset PyTorch (`ACOSPairDataset`)\n",
    "\n",
    " 2. L'Architettura Custom (`ModernBertACOSClassifier`)\n",
    "\n",
    " 3. Inizializzazione e DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b46c0",
   "metadata": {},
   "source": [
    "### 1. Il Dataset PyTorch (`ACOSPairDataset`)\n",
    "Questa classe si occupa di \"impacchettare\" i dati per la rete neurale. \n",
    "Legge le coppie salvate nei file `.pkl`, passa il testo nel Tokenizer di ModernBERT e trasforma tutto in **Tensori PyTorch**. Nota chiave: legge direttamente gli indici degli span (che ho gi√† corretto con l'offset `+1` per far spazio al token `[CLS]`) e carica l'array di 121 etichette (le \"soluzioni\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a13b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ACOSPairDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row['review_text']\n",
    "        \n",
    "        # Gli span sono gi√† corretti con il +1 per il [CLS]!\n",
    "        a_span = row['aspect_span']\n",
    "        o_span = row['opinion_span']\n",
    "\n",
    "        # Tokenizzazione (ModernBERT usa il token [CLS] in automatico)\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        labels = torch.tensor(row['labels'], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'aspect_span': torch.tensor(a_span),\n",
    "            'opinion_span': torch.tensor(o_span),\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe6e74",
   "metadata": {},
   "source": [
    "### 2. L'Architettura Custom (`ModernBertACOSClassifier`)\n",
    "Questa √® la vera \"magia\" matematica del paper, tradotta in codice:\n",
    "* **Il Corpo (Backbone):** Invece di partire da zero, carichiamo il *corpo* del modello che hai gi√† addestrato nello Step 1 (`best_model_laptop`). In questo modo, la rete conosce gi√† il dominio tecnico dei computer!\n",
    "* **Span Pooling:** Il modello estrae i vettori (hidden states) corrispondenti alle parole dell'Aspetto e dell'Opinione e ne calcola la media. Se un elemento √® implicito (`-1`), pesca automaticamente il vettore globale del token `[CLS]`.\n",
    "* **Feature Fusion:** Concatena il vettore dell'aspetto ($u_a$) e dell'opinione ($u_o$) in un unico grande vettore di dimensione 1536.\n",
    "* **Le 121 Teste (Multiple Multi-class):** Passa questo vettore in 121 classificatori lineari paralleli. Ognuno di essi decider√† se per la *sua* categoria la coppia √® `Positive (0)`, `Negative (1)`, `Neutral (2)` o `Invalid (3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8a0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class ModernBertACOSClassifier(nn.Module):\n",
    "    def __init__(self, path_to_best_model, num_categories):\n",
    "        super(ModernBertACOSClassifier, self).__init__()\n",
    "        \n",
    "        # Carichiamo SOLO IL CORPO dal tuo modello dello Step 1\n",
    "        self.modernbert = AutoModel.from_pretrained(path_to_best_model)\n",
    "        hidden_size = self.modernbert.config.hidden_size # 768\n",
    "        \n",
    "        # Le 121 teste (ognuna prende il vettore concatenato 1536 e sputa 4 classi)\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(hidden_size * 2, 4) for _ in range(num_categories)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, aspect_spans, opinion_spans):\n",
    "        outputs = self.modernbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state # [Batch, Seq_Len, 768]\n",
    "        \n",
    "        batch_size = last_hidden_state.size(0)\n",
    "        u_a_list, u_o_list = [], []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Pooling Aspetto\n",
    "            a_start, a_end = aspect_spans[i]\n",
    "            if a_start == -1: \n",
    "                u_a = last_hidden_state[i, 0, :] # Token [CLS]\n",
    "            else:\n",
    "                u_a = last_hidden_state[i, a_start:a_end, :].mean(dim=0)\n",
    "            \n",
    "            # Pooling Opinione\n",
    "            o_start, o_end = opinion_spans[i]\n",
    "            if o_start == -1: \n",
    "                u_o = last_hidden_state[i, 0, :] # Token [CLS]\n",
    "            else:\n",
    "                u_o = last_hidden_state[i, o_start:o_end, :].mean(dim=0)\n",
    "            \n",
    "            u_a_list.append(u_a)\n",
    "            u_o_list.append(u_o)\n",
    "\n",
    "        # Concatenazione: [u_a ; u_o]\n",
    "        combined_features = torch.cat((torch.stack(u_a_list), torch.stack(u_o_list)), dim=-1)\n",
    "        combined_features = self.dropout(combined_features)\n",
    "\n",
    "        # Passiamo il vettore nelle teste lineari\n",
    "        logits = [head(combined_features) for head in self.heads]\n",
    "        \n",
    "        # Output: [Batch, 121, 4]\n",
    "        return torch.stack(logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ebed1d",
   "metadata": {},
   "source": [
    "### 3. Inizializzazione e DataLoaders\n",
    "L'ultimo blocco carica fisicamente i file salvati dalla nostra \"Fabbrica dei Dati\", istanzia i `Dataset`, e crea i `DataLoader` (con batch size = 16) per \"nutrire\" la GPU in modo efficiente durante l'addestramento. Infine, sposta il modello sulla scheda video (CUDA) pronto per il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2509e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42fa451d34e4a7f82673d15a65a8dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mModernBertModel LOAD REPORT\u001b[0m from: ./best_model_restaurant\n",
      "Key               | Status     |  | \n",
      "------------------+------------+--+-\n",
      "classifier.weight | UNEXPECTED |  | \n",
      "head.norm.weight  | UNEXPECTED |  | \n",
      "head.dense.weight | UNEXPECTED |  | \n",
      "classifier.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello inizializzato! Categorie: 13 | Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Carichiamo la lista delle categorie salvata prima\n",
    "with open(\"data_coppie/restaurant_categories.pkl\", \"rb\") as f:\n",
    "    category_list = pickle.load(f)\n",
    "num_categories = len(category_list) # 121\n",
    "\n",
    "# 2. Carichiamo i DataFrame di Train e Dev\n",
    "df_train = pd.read_pickle(\"data_coppie/train_restaurant_pairs.pkl\")\n",
    "df_dev = pd.read_pickle(\"data_coppie/dev_restaurant_pairs.pkl\")\n",
    "df_test = pd.read_pickle(\"data_coppie/test_restaurant_pairs.pkl\")\n",
    "\n",
    "# 3. Inizializziamo il Tokenizer e i Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "train_dataset = ACOSPairDataset(df_train, tokenizer)\n",
    "dev_dataset = ACOSPairDataset(df_dev, tokenizer)\n",
    "test_dataset = ACOSPairDataset(df_test, tokenizer) \n",
    "\n",
    "# 4. Creiamo i DataLoader (Batch size 16 √® un buon compromesso tra velocit√† e VRAM)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dev_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16) \n",
    "# 5. Inizializziamo il Modello usando i pesi dello Step 1!\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ModernBertACOSClassifier(\"./best_model_restaurant\", num_categories)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Modello inizializzato! Categorie: {num_categories} | Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834f631",
   "metadata": {},
   "source": [
    "## WANDB per lo step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274d34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristinatomaciello2001\u001b[0m (\u001b[33mcristinatextmining\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/al3th3ia/Scrivania/Cristina/progetto-text-mining/wandb/run-20260221_151513-bofd34hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/bofd34hf' target=\"_blank\">Step2_Class_answerdotai/ModernBERT-base_Restaurant-ACOS</a></strong> to <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/bofd34hf' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/bofd34hf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " W&B inizializzato per il progetto: BigData-TextMining-ACOS\n",
      "Nome della Run attuale: Step2_Class_answerdotai/ModernBERT-base_Restaurant-ACOS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chiudiamo per sicurezza qualsiasi run precedente rimasta aperta nello stesso notebook\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "\n",
    "WANDB_ENTITY = \"cristinatextmining\"\n",
    "\n",
    "# 1. Definizione degli Hyperparameters per lo STEP 2\n",
    "config_step2 = {\n",
    "    \"learning_rate\": 2e-5, # Solitamente per lo Step 2 un LR leggermente pi√π basso √® meglio (es. 2e-5)\n",
    "    \"epochs\": 40,\n",
    "    \"batch_size\": 16,\n",
    "    \"accumulation_steps\": 4, # Aggiunto per il tuo training loop ottimizzato!\n",
    "    \"model_name\": \"answerdotai/ModernBERT-base\",\n",
    "    \"dataset\": \"Restaurant-ACOS\", \n",
    "    \"seed\": 42,\n",
    "    \"patience\": 2  # Per Early Stopping\n",
    "}\n",
    "\n",
    "# 2. Inizializzazione del Run per lo Step 2\n",
    "wandb.init(\n",
    "    project=\"BigData-TextMining-ACOS\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    config=config_step2,\n",
    "    # Aggiungiamo \"Step2_Class\" al nome per distinguerlo dallo Step 1\n",
    "    name=f\"Step2_Class_{config_step2['model_name']}_{config_step2['dataset']}\" \n",
    ")\n",
    "\n",
    "print(f\" W&B inizializzato per il progetto: {wandb.run.project}\")\n",
    "print(f\"Nome della Run attuale: {wandb.run.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f483c",
   "metadata": {},
   "source": [
    "## Train su Sentiment e Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ca2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training STEP 2 su RESTAURANT: 40 epoche | Device: cuda\n",
      "Accumulo Gradienti ogni 4 step | FP16 Attivato\n",
      "\n",
      "--- Epoca 1/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:49<00:00,  4.71it/s, loss=0.567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1117 | Valid Loss: 0.8788\n",
      "Miglior modello trovato (Loss: 0.8788)! Salvataggio...\n",
      "\n",
      "--- Epoca 2/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:48<00:00,  4.82it/s, loss=1.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7352 | Valid Loss: 0.7438\n",
      "Miglior modello trovato (Loss: 0.7438)! Salvataggio...\n",
      "\n",
      "--- Epoca 3/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:50<00:00,  4.56it/s, loss=1.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5610 | Valid Loss: 0.6204\n",
      "Miglior modello trovato (Loss: 0.6204)! Salvataggio...\n",
      "\n",
      "--- Epoca 4/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:51<00:00,  4.55it/s, loss=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4305 | Valid Loss: 0.6102\n",
      "Miglior modello trovato (Loss: 0.6102)! Salvataggio...\n",
      "\n",
      "--- Epoca 5/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:50<00:00,  4.58it/s, loss=0.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3276 | Valid Loss: 0.6053\n",
      "Miglior modello trovato (Loss: 0.6053)! Salvataggio...\n",
      "\n",
      "--- Epoca 6/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:50<00:00,  4.62it/s, loss=0.0956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2656 | Valid Loss: 0.5586\n",
      "Miglior modello trovato (Loss: 0.5586)! Salvataggio...\n",
      "\n",
      "--- Epoca 7/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:53<00:00,  4.30it/s, loss=0.127] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1990 | Valid Loss: 0.5811\n",
      "Nessun miglioramento. Patience: 1/2\n",
      "\n",
      "--- Epoca 8/40 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232/232 [00:51<00:00,  4.50it/s, loss=0.548] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1591 | Valid Loss: 0.5653\n",
      "Nessun miglioramento. Patience: 2/2\n",
      "\n",
      "EARLY STOPPING ATTIVATO! Interruzione all'epoca 8.\n",
      "\n",
      "Fine Addestramento Step 2 (Restaurant).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà</td></tr><tr><td>train_loss_epoch</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>valid_loss_epoch</td><td>‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.54834</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>train_loss_epoch</td><td>0.15911</td></tr><tr><td>valid_loss_epoch</td><td>0.56527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Step2_Class_answerdotai/ModernBERT-base_Restaurant-ACOS</strong> at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/bofd34hf' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/bofd34hf</a><br> View project at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260221_151513-bofd34hf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import bitsandbytes as bnb\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# --- 1. CONFIGURAZIONE AVANZATA MEMORIA ---\n",
    "\n",
    "# Gradient Checkpointing: abilitato SOLO sul corpo di ModernBERT\n",
    "model.modernbert.gradient_checkpointing_enable()\n",
    "\n",
    "# Parametri per simulare un batch size maggiore\n",
    "accumulation_steps = config_step2.get('accumulation_steps', 4) \n",
    "patience = config_step2.get('patience', 2)\n",
    "patience_counter = 0\n",
    "\n",
    "# Ottimizzatore AdamW a 8-bit\n",
    "optimizer = bnb.optim.AdamW8bit(\n",
    "    model.parameters(), \n",
    "    lr=config_step2['learning_rate']\n",
    ")\n",
    "\n",
    "# Scaler per Mixed Precision (fondamentale per evitare l'OOM)\n",
    "scaler = GradScaler() \n",
    "\n",
    "# La Loss pesata per contrastare lo sbilanciamento delle classi\n",
    "weights = torch.tensor([150.0, 400.0, 100.0, 1.0]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# Calcolo degli step totali per lo scheduler\n",
    "total_steps = (len(train_loader) // accumulation_steps) * config_step2['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# --- 2. FUNZIONI DI SUPPORTO OTTIMIZZATE (STEP 2) ---\n",
    "\n",
    "def evaluate_model_step2(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            aspect_span = batch['aspect_span'].to(device)\n",
    "            opinion_span = batch['opinion_span'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda'):\n",
    "                logits = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                               aspect_spans=aspect_span, opinion_spans=opinion_span)\n",
    "                \n",
    "                loss = criterion(logits.view(-1, 4), labels.view(-1))\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def train_epoch_step2(model, data_loader, optimizer, scheduler, criterion, device, epoch_idx, scaler, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad() \n",
    "    \n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    \n",
    "    for i, batch in enumerate(loop):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        aspect_span = batch['aspect_span'].to(device)\n",
    "        opinion_span = batch['opinion_span'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        with autocast(device_type='cuda'):\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                           aspect_spans=aspect_span, opinion_spans=opinion_span)\n",
    "            \n",
    "            loss = criterion(logits.view(-1, 4), labels.view(-1))\n",
    "            loss = loss / accumulation_steps \n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        real_loss = loss.item() * accumulation_steps\n",
    "        total_loss += real_loss\n",
    "        \n",
    "        wandb.log({\"batch_loss\": real_loss})\n",
    "        loop.set_description(f\"Epoca {epoch_idx + 1}\")\n",
    "        loop.set_postfix(loss=real_loss)\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# --- 3. CICLO DI ADDESTRAMENTO ---\n",
    "\n",
    "print(f\"Training STEP 2 su RESTAURANT: {config_step2['epochs']} epoche | Device: {device}\")\n",
    "print(f\"Accumulo Gradienti ogni {accumulation_steps} step | FP16 Attivato\")\n",
    "\n",
    "best_valid_loss_restaurant = float('inf')\n",
    "\n",
    "for epoch in range(config_step2['epochs']):\n",
    "    print(f\"\\n--- Epoca {epoch+1}/{config_step2['epochs']} ---\")\n",
    "    \n",
    "    # 1. Training\n",
    "    train_loss_restaurant = train_epoch_step2(\n",
    "        model, train_loader, optimizer, scheduler, criterion, \n",
    "        device, epoch, scaler, accumulation_steps\n",
    "    )\n",
    "    \n",
    "    # 2. Validazione\n",
    "    valid_loss_restaurant = evaluate_model_step2(model, val_loader, criterion, device)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss_restaurant:.4f} | Valid Loss: {valid_loss_restaurant:.4f}\")\n",
    "    \n",
    "    # 3. Log metriche epoca su W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss_epoch\": train_loss_restaurant,\n",
    "        \"valid_loss_epoch\": valid_loss_restaurant\n",
    "    })\n",
    "    \n",
    "    # --- LOGICA EARLY STOPPING & CHECKPOINT ---\n",
    "    \n",
    "    if valid_loss_restaurant < best_valid_loss_restaurant:\n",
    "        best_valid_loss_restaurant = valid_loss_restaurant\n",
    "        patience_counter = 0  \n",
    "        \n",
    "        print(f\"Miglior modello trovato (Loss: {best_valid_loss_restaurant:.4f})! Salvataggio...\")\n",
    "        \n",
    "        # Salvataggio custom model nella cartella dei RESTAURANT\n",
    "        save_dir = \"./best_classifier_restaurant\"\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"pytorch_model.bin\"))\n",
    "        \n",
    "    else:\n",
    "        patience_counter += 1  \n",
    "        print(f\"Nessun miglioramento. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEARLY STOPPING ATTIVATO! Interruzione all'epoca {epoch+1}.\")\n",
    "            break \n",
    "\n",
    "print(\"\\nFine Addestramento Step 2 (Restaurant).\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac5bb2",
   "metadata": {},
   "source": [
    "## Test su Sentiment e Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7ee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/al3th3ia/Scrivania/Cristina/progetto-text-mining/wandb/run-20260221_152253-ecccilye</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/ecccilye' target=\"_blank\">TEST_Step2_answerdotai/ModernBERT-base_Restaurant-ACOS</a></strong> to <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/ecccilye' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/ecccilye</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio Test (RESTAURANT) sul Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b95160b6af45dd9f3c30b55829df40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mModernBertModel LOAD REPORT\u001b[0m from: ./best_model_restaurant\n",
      "Key               | Status     |  | \n",
      "------------------+------------+--+-\n",
      "classifier.weight | UNEXPECTED |  | \n",
      "head.norm.weight  | UNEXPECTED |  | \n",
      "head.dense.weight | UNEXPECTED |  | \n",
      "classifier.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHECK CARICAMENTO PESI ---\n",
      "Chiavi Inaspettate (OK se sono dello Step 1): 0\n",
      "Chiavi Mancanti (PROBLEMA se sono 'heads'): 0\n",
      "SUCCESS: Le teste di classificazione (Sentiment) sono state caricate correttamente.\n",
      "Calcolo predizioni con Soglia di Confidenza al 90.0%...\n",
      "\n",
      "==================================================\n",
      "REPORT FINALE DEL CLASSIFICATORE (Step 2 - RESTAURANT)\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Positive (0)       0.30      0.32      0.31       205\n",
      "Negative (1)       0.00      0.00      0.00        44\n",
      " Neutral (2)       0.46      0.55      0.50       667\n",
      "\n",
      "   micro avg       0.43      0.47      0.45       916\n",
      "   macro avg       0.25      0.29      0.27       916\n",
      "weighted avg       0.40      0.47      0.43       916\n",
      "\n",
      "MICRO F1-Score (Sentiment Corretto): 0.4478\n",
      "MACRO F1-Score (Media delle classi): 0.2704\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>confidence_threshold</td><td>‚ñÅ</td></tr><tr><td>test_macro_f1</td><td>‚ñÅ</td></tr><tr><td>test_micro_f1</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>confidence_threshold</td><td>0.9</td></tr><tr><td>test_macro_f1</td><td>0.2704</td></tr><tr><td>test_micro_f1</td><td>0.44778</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TEST_Step2_answerdotai/ModernBERT-base_Restaurant-ACOS</strong> at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/ecccilye' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/ecccilye</a><br> View project at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260221_152253-ecccilye/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Chiudiamo run appese\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "\n",
    "WANDB_ENTITY = \"cristinatextmining\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"BigData-TextMining-ACOS\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    # Chiamo la run con il prefisso \"TEST_\"\n",
    "    name=f\"TEST_Step2_{config_step2['model_name']}_{config_step2['dataset']}\",\n",
    "    job_type=\"test\"\n",
    ")\n",
    "\n",
    "# --- 1. PREPARAZIONE ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Avvio Test (RESTAURANT) sul Device: {device}\")\n",
    "\n",
    "# Ricreiamo l'architettura del modello puntando alla cartella base dei ristoranti\n",
    "num_categories = len(category_list)\n",
    "model_test = ModernBertACOSClassifier(\"./best_model_restaurant\", num_categories)\n",
    "\n",
    "# Carichiamo i pesi dello Step 2 appena addestrati per i ristoranti\n",
    "model_path = \"./best_classifier_restaurant/pytorch_model.bin\"\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "\n",
    "# USIAMO STRICT=FALSE\n",
    "missing_keys, unexpected_keys = model_test.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "print(\"\\n--- CHECK CARICAMENTO PESI ---\")\n",
    "print(f\"Chiavi Inaspettate (OK se sono dello Step 1): {len(unexpected_keys)}\")\n",
    "print(f\"Chiavi Mancanti (PROBLEMA se sono 'heads'): {len(missing_keys)}\")\n",
    "\n",
    "# Verifica specifica sulle teste\n",
    "heads_missing = [k for k in missing_keys if \"heads\" in k]\n",
    "if heads_missing:\n",
    "    print(f\"ERRORE CRITICO: Le teste di classificazione non sono state caricate! {heads_missing[:5]}\")\n",
    "else:\n",
    "    print(\"SUCCESS: Le teste di classificazione (Sentiment) sono state caricate correttamente.\")\n",
    "    \n",
    "model_test.to(device)\n",
    "model_test.eval()\n",
    "\n",
    "# --- 2. ESTRAZIONE PROBABILITA' (UNA SOLA VOLTA) ---\n",
    "print(\"Estrazione di tutte le probabilit√† dal modello in corso (attendere)...\")\n",
    "\n",
    "all_probs_list = []\n",
    "all_true_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader: \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        aspect_span = batch['aspect_span'].to(device)\n",
    "        opinion_span = batch['opinion_span'].to(device)\n",
    "        labels = batch['labels'].to(device) \n",
    "        \n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            logits = model_test(input_ids, attention_mask, aspect_span, opinion_span)\n",
    "            \n",
    "        # Trasformiamo i logits in probabilit√† e li portiamo su CPU per non intasarla\n",
    "        probs = torch.softmax(logits, dim=-1).cpu() \n",
    "        \n",
    "        all_probs_list.append(probs)\n",
    "        all_true_list.append(labels.cpu())\n",
    "\n",
    "# Uniamo tutti i batch in un unico grande blocco di memoria\n",
    "all_probs = torch.cat(all_probs_list, dim=0) \n",
    "all_true = torch.cat(all_true_list, dim=0).numpy().flatten()\n",
    "\n",
    "\n",
    "# --- 3. GRID SEARCH SUL THRESHOLD ---\n",
    "print(\"\\nAvvio Grid Search per la migliore Soglia di Confidenza...\")\n",
    "\n",
    "thresholds_to_test = np.arange(0.75, 0.96, 0.05)\n",
    "best_micro_f1 = 0.0\n",
    "best_macro_f1 = 0.0\n",
    "best_threshold = 0.0\n",
    "best_report = \"\"\n",
    "\n",
    "target_names = ['Positive (0)', 'Negative (1)', 'Neutral (2)']\n",
    "labels_to_eval = [0, 1, 2]\n",
    "\n",
    "for thresh in thresholds_to_test:\n",
    "    # Troviamo la probabilit√† massima tra le classi valide (0, 1, 2)\n",
    "    valid_class_probs, valid_class_preds = torch.max(all_probs[:, :, :3], dim=-1)\n",
    "    \n",
    "    # Creiamo un tensore pieno di 3 (Invalid)\n",
    "    final_preds = torch.full_like(valid_class_preds, 3)\n",
    "    \n",
    "    # Applichiamo la soglia corrente\n",
    "    mask = valid_class_probs > thresh\n",
    "    final_preds[mask] = valid_class_preds[mask]\n",
    "    \n",
    "    preds_flat = final_preds.numpy().flatten()\n",
    "    \n",
    "    # Calcoliamo il Micro F1-Score\n",
    "    current_micro_f1 = f1_score(all_true, preds_flat, labels=labels_to_eval, average='micro')\n",
    "    \n",
    "    # Se √® il migliore visto finora, salviamo tutto\n",
    "    if current_micro_f1 > best_micro_f1:\n",
    "        best_micro_f1 = current_micro_f1\n",
    "        best_threshold = thresh\n",
    "        best_macro_f1 = f1_score(all_true, preds_flat, labels=labels_to_eval, average='macro')\n",
    "        best_report = classification_report(\n",
    "            all_true, preds_flat, labels=labels_to_eval, \n",
    "            target_names=target_names, zero_division=0\n",
    "        )\n",
    "\n",
    "# --- 4. STAMPA DEI RISULTATI VINCITORI E LOG W&B ---\n",
    "print(\"\\n\" + \"üèÜ\"*25)\n",
    "print(f\"IL VINCITORE √à... THRESHOLD A {best_threshold:.2f} ({(best_threshold*100):.0f}%)\")\n",
    "print(\"üèÜ\"*25)\n",
    "\n",
    "print(\"\\n--- MIGLIOR CLASSIFICATION REPORT ---\")\n",
    "print(best_report)\n",
    "print(f\"BEST MICRO F1-Score: {best_micro_f1:.4f}\")\n",
    "print(f\"CORRISPONDENTE MACRO F1: {best_macro_f1:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Salviamo solo il vincitore su Weights & Biases\n",
    "wandb.log({\n",
    "    \"best_test_micro_f1\": best_micro_f1,\n",
    "    \"best_test_macro_f1\": best_macro_f1,\n",
    "    \"optimal_threshold\": best_threshold\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556e5382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "url = \"data_coppie/test_restaurant_pairs.pkl\"\n",
    "df = pd.read_pickle(url)\n",
    "df.sample(5)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# 1. Estraiamo tutti i singoli valori dalle liste della colonna 'labels'\n",
    "all_labels = []\n",
    "for row in df['labels']:\n",
    "    # Se i dati sono stringhe, usiamo ast.literal_eval per convertirli in liste\n",
    "    if isinstance(row, str):\n",
    "        l = ast.literal_eval(row)\n",
    "    else:\n",
    "        l = row\n",
    "    all_labels.extend(l)\n",
    "\n",
    "# 2. Contiamo le occorrenze di ogni classe\n",
    "unique, counts = np.unique(all_labels, return_counts=True)\n",
    "label_map = {0: 'Positive (0)', 1: 'Negative (1)', 2: 'Neutral (2)', 3: 'Invalid (3)'}\n",
    "names = [label_map.get(x, f\"Classe {x}\") for x in unique]\n",
    "\n",
    "# 3. Creazione del Grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#2ca02c', '#d62728', '#1f77b4', '#7f7f7f'] # Verde, Rosso, Blu, Grigio\n",
    "bars = plt.bar(names, counts, color=colors[:len(names)])\n",
    "\n",
    "# Aggiungiamo i valori numerici sopra ogni barra\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + (max(counts)*0.01), \n",
    "             int(yval), ha='center', fontweight='bold')\n",
    "\n",
    "plt.title('Distribuzione delle Etichette (Step 2: Sentiment)', fontsize=14)\n",
    "plt.ylabel('Frequenza (Numero di occorrenze)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
