{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61db207b",
   "metadata": {},
   "source": [
    "# ACOS-ABSA: Unified Preprocessing Pipeline for ModernBERT\n",
    "\n",
    "1. Il paper originale utilizza BERT-base-uncased (Devlin et al., 2018) come encoder principale. Sebbene rivoluzionario all'epoca, BERT ha un contesto limitato (512 token) e una capacità di generalizzazione inferiore rispetto ai modelli attuali.\n",
    "\n",
    "    * **La Nostra Soluzione:** Utilizziamo ModernBERT-base, un modello State-of-the-Art (2024) addestrato su un corpus molto più vasto e con una finestra di contesto estesa (8k token).\n",
    "\n",
    "    * **Vantaggio:** ModernBERT offre rappresentazioni contestuali più ricche, fondamentali per risolvere il problema degli Aspetti Impliciti (es. dedurre Price da \"it is expensive\"), che rappresentano una sfida critica nel dataset ACOS.\n",
    "+1\n",
    "\n",
    "2. Strategia di Allineamento Sub-word (Robust Tokenization)\n",
    "Il paper gestisce l'allineamento tra parole e token, ma spesso i modelli standard soffrono quando una parola annotata (es. \"difficulty\") viene spezzata in più sub-token (diffic, ##ulty).\n",
    "\n",
    "    * **La Nostra Soluzione:** Abbiamo implementato una pipeline di preprocessing personalizzata che utilizza i word_ids per mappare precisamente le etichette BIO sui sub-token.\n",
    "\n",
    "    * **Vantaggio:** Questo garantisce che nessun'informazione venga persa durante la tokenizzazione: se una parola è un'Opinione, tutti i suoi frammenti (token) erediteranno correttamente l'etichetta, migliorando la Recall del modello.\n",
    "\n",
    "3. Semplificazione Architetturale (Rimozione del CRF)\n",
    "Il modello Extract-Classify-ACOS impiega un layer CRF (Conditional Random Field) sopra BERT per \"pulire\" la sequenza di tag predetti e imporre vincoli logici.\n",
    "\n",
    "   * **La Nostra Soluzione:** Sfruttando la maggiore potenza di estrazione delle feature di ModernBERT, iniziamo con una Linear Classification Head standard.\n",
    "\n",
    "   * **Vantaggio:** Questo riduce drasticamente la complessità computazionale e i tempi di addestramento/inferenza. La capacità superiore di ModernBERT di apprendere le dipendenze locali rende spesso superfluo l'uso di un CRF, permettendo al modello di apprendere i vincoli BIO direttamente dai dati.\n",
    "\n",
    "4. Gestione \"Native\" degli Span Impliciti\n",
    "Come evidenziato nel paper, una larga percentuale di quadruple contiene aspetti o opinioni implicite (Span Nulli).\n",
    "\n",
    "    * **La Nostra Soluzione:** Il nostro preprocessing gestisce esplicitamente gli span (-1, -1) nel dataset, preparando il terreno per la fase successiva (Classificazione). Mentre la fase di estrazione corrente si concentra sugli span espliciti, i vettori [CLS] di ModernBERT sono già ottimizzati per catturare il contesto globale necessario a predire le categorie implicite nel secondo step della pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffaf0de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate.\n"
     ]
    }
   ],
   "source": [
    "# Import delle librerie necessarie\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "print(\"Librerie caricate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85b8df",
   "metadata": {},
   "source": [
    "### Impostazioni per la riproducibilità "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929fd2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seeds impostati su 42.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Imposto i seed per la riproducibilità.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        # Imposto anche i seed per la GPU, se disponibile\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# Esegui l'impostazione del seed\n",
    "set_seed(42) \n",
    "print(\"Random seeds impostati su 42.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59542d4c",
   "metadata": {},
   "source": [
    "## Raw Data Parsing & Quadruple Decoding\n",
    "\n",
    "### Caricamento dei 3 dataset LAPTOP-ACOS e dei 3 dataset RESTAURANT-ACOS\n",
    "Questa cella è dedicata al caricamento dei dataset TSV di ACOS (Training, Development e Test) dalla directory locale.\n",
    "\n",
    "Data la struttura complessa del file di annotazione, che contiene tabulazioni (\\t) interne e un numero variabile di quadruple per riga, la funzione load_as_single_string adotta una strategia di caricamento flessibile:\n",
    "\n",
    "1. **Forzatura Stringa Unica:** Viene utilizzato un separatore inesistente (\\x07) per istruire Pandas a caricare l'intera riga TSV come una singola colonna stringa *(full_line_data).*\n",
    "\n",
    "2. **Robustezza:** Questo approccio previene i comuni ParserError causati da tabulazioni o delimitatori sporchi interni, garantendo che i dati grezzi vengano letti completamente senza perdita.\n",
    "\n",
    "L'output di questa cella sono i tre DataFrame *(df_train, df_dev, df_test)*, ciascuno pronto per il parsing sequenziale sul contenuto della colonna full_line_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a9c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File laptop_train_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_dev_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_test_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_train_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_dev_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_test_quad_bert.tsv caricato come 1 colonna unica.\n",
      "Caricamento Flessibile Completato.\n",
      "(2934, 1) (326, 1) (816, 1)\n",
      "(1530, 1) (171, 1) (583, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definisci il percorso per ACOS\n",
    "DATA_DIR_ACOS = 'data/Laptop-ACOS/'\n",
    "\n",
    "# Definisci i percorsi completi dei file\n",
    "TRAIN_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_train_quad_bert.tsv')\n",
    "DEV_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_dev_quad_bert.tsv')\n",
    "TEST_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_test_quad_bert.tsv')\n",
    "\n",
    "# Definisci il percorso REESTAURANT\n",
    "DATA_DIR_RESTAURANT = 'data/Restaurant-ACOS/'\n",
    "\n",
    "# Definisci i percorsi completi dei file\n",
    "TRAIN_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_train_quad_bert.tsv')\n",
    "DEV_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_dev_quad_bert.tsv')\n",
    "TEST_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_test_quad_bert.tsv')\n",
    "\n",
    "def load_as_single_string(path):\n",
    "    \"\"\"\n",
    "    Carica l'intero file TSV in un'unica colonna stringa, forzando la lettura riga per riga, \n",
    "    per evitare errori di parsing dovuti a delimitatori interni.\n",
    "    \"\"\"\n",
    "    # 1. Utilizza read_csv ma forza l'uso di un separatore inesistente e non usare header\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        sep='\\x07', # Separa per un carattere inesistente (Bell character)\n",
    "        header=None, \n",
    "        on_bad_lines='skip', # Ignora le righe che danno problemi di formattazione\n",
    "        engine='python'\n",
    "    )\n",
    "    \n",
    "    # Rinomina l'unica colonna che contiene l'intera riga TSV\n",
    "    df.columns = ['full_line_data']    \n",
    "    print(f\"File {path.split('/')[-1]} caricato come {df.shape[1]} colonna unica.\")\n",
    "    return df\n",
    "\n",
    "# Esecuzione del caricamento corretto\n",
    "try:\n",
    "    df_train_laptop = load_as_single_string(TRAIN_FILE_PATH_ACOS)\n",
    "    df_dev_laptop = load_as_single_string(DEV_FILE_PATH_ACOS)\n",
    "    df_test_laptop = load_as_single_string(TEST_FILE_PATH_ACOS)\n",
    "    \n",
    "    df_train_rest = load_as_single_string(TRAIN_FILE_PATH_RESTAURANT)\n",
    "    df_dev_rest = load_as_single_string(DEV_FILE_PATH_RESTAURANT)\n",
    "    df_test_rest = load_as_single_string(TEST_FILE_PATH_RESTAURANT)\n",
    "    \n",
    "    print(\"Caricamento Flessibile Completato.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Errore critico durante il caricamento: {e}\")\n",
    "    raise\n",
    "\n",
    "print(df_train_laptop.shape, df_dev_laptop.shape, df_test_laptop.shape)\n",
    "print(df_train_rest.shape, df_dev_rest.shape, df_test_rest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351044b",
   "metadata": {},
   "source": [
    "### Pipeline di Parsing e Strutturazione dei Dati(Quadruple)\n",
    "Questa sezione implementa la pipeline di pre-elaborazione finale che trasforma la riga grezza di input in un formato Python strutturato, pronto per la Tokenizzazione del modello ModernBERT.\n",
    "\n",
    "Il codice esegue un processo a due fasi per ogni riga del dataset:\n",
    "\n",
    "1. **Separazione (Parsing della Riga Grezza)**: Esegue la divisione della riga unica *(full_line_data)* utilizzando il separatore Tab (\\t). Questo isola la recensione pulita *(review_text)* dalla stringa contenente le quadruple codificate (il target).\n",
    "\n",
    "2. **Decodifica Strutturale (Deep Parsing)**: Applica la funzione *parse_target_quadruples* alla stringa target. Questa funzione scompone la stringa in un dizionario con chiavi chiare **(span_A, span_B, category_aspect, sentiment)**, gestendo gli Indici Span Nullo (-1,-1) e validando la struttura a 4 elementi.\n",
    "\n",
    "L'output finale è il DataFrame pulito con la colonna parsed_quadruples, che contiene le informazioni di target necessarie per creare le label di Sequence Labeling nella fase successiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e49f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creazione delle copie e avvio del parsing...\n",
      "Parsing completato con successo.\n",
      "Salvataggio dei dataset parsati nella cartella 'data_parsing'...\n",
      "Dataset Laptop salvati!\n",
      "Dataset Restaurant salvati!\n",
      "\n",
      "Anteprima del DataFrame di Test (df_test_parsing_laptop):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>parsed_quadruples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the unit cost $ 275 to start with , so it is n...</td>\n",
       "      <td>[{'span_A': (1, 2), 'span_B': (12, 14), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going from ace ##r 15 to ace ##r 11 was diffic...</td>\n",
       "      <td>[{'span_A': (6, 9), 'span_B': (10, 11), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also it ' s not a true ss ##d drive in there b...</td>\n",
       "      <td>[{'span_A': (7, 10), 'span_B': (-1, -1), 'cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the computer has difficulty switching between ...</td>\n",
       "      <td>[{'span_A': (1, 2), 'span_B': (3, 4), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 / 28 / 18 - a couple days ago i updated the ...</td>\n",
       "      <td>[{'span_A': (13, 15), 'span_B': (-1, -1), 'cat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  the unit cost $ 275 to start with , so it is n...   \n",
       "1  going from ace ##r 15 to ace ##r 11 was diffic...   \n",
       "2  also it ' s not a true ss ##d drive in there b...   \n",
       "3  the computer has difficulty switching between ...   \n",
       "4  2 / 28 / 18 - a couple days ago i updated the ...   \n",
       "\n",
       "                                   parsed_quadruples  \n",
       "0  [{'span_A': (1, 2), 'span_B': (12, 14), 'categ...  \n",
       "1  [{'span_A': (6, 9), 'span_B': (10, 11), 'categ...  \n",
       "2  [{'span_A': (7, 10), 'span_B': (-1, -1), 'cate...  \n",
       "3  [{'span_A': (1, 2), 'span_B': (3, 4), 'categor...  \n",
       "4  [{'span_A': (13, 15), 'span_B': (-1, -1), 'cat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anteprima del DataFrame di Test (df_test_parsing_rest):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>parsed_quadruples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yu ##m !</td>\n",
       "      <td>[{'span_A': (-1, -1), 'span_B': (0, 2), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serves really good su ##shi .</td>\n",
       "      <td>[{'span_A': (3, 5), 'span_B': (2, 3), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the biggest portions but adequate .</td>\n",
       "      <td>[{'span_A': (3, 4), 'span_B': (0, 3), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green tea cr ##eme br ##ule ##e is a must !</td>\n",
       "      <td>[{'span_A': (0, 7), 'span_B': (9, 10), 'catego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it has great su ##shi and even better service .</td>\n",
       "      <td>[{'span_A': (3, 5), 'span_B': (2, 3), 'categor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_text  \\\n",
       "0                                         yu ##m !   \n",
       "1                    serves really good su ##shi .   \n",
       "2          not the biggest portions but adequate .   \n",
       "3      green tea cr ##eme br ##ule ##e is a must !   \n",
       "4  it has great su ##shi and even better service .   \n",
       "\n",
       "                                   parsed_quadruples  \n",
       "0  [{'span_A': (-1, -1), 'span_B': (0, 2), 'categ...  \n",
       "1  [{'span_A': (3, 5), 'span_B': (2, 3), 'categor...  \n",
       "2  [{'span_A': (3, 4), 'span_B': (0, 3), 'categor...  \n",
       "3  [{'span_A': (0, 7), 'span_B': (9, 10), 'catego...  \n",
       "4  [{'span_A': (3, 5), 'span_B': (2, 3), 'categor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quadruple decodificate: [{'span_A': (0, 7), 'span_B': (9, 10), 'category_aspect': 'FOOD#QUALITY', 'sentiment': 2}]\n",
      "Testo corrispondente: green tea cr ##eme br ##ule ##e is a must !\n",
      "\n",
      "Dimensioni finali (Train, Dev, Test):\n",
      "(2934, 2) (326, 2) (816, 2)\n",
      "(1530, 2) (171, 2) (583, 2)\n"
     ]
    }
   ],
   "source": [
    "# --- I. DEFINIZIONE DELLE FUNZIONI DI PARSING ---\n",
    "\n",
    "def parse_target_quadruples(target_string):\n",
    "    \"\"\"\n",
    "    Decodifica la stringa di una singola quadrupla in un dizionario strutturato.\n",
    "    \"\"\"\n",
    "    if not target_string:\n",
    "        return {} \n",
    "\n",
    "    parts = target_string.split()\n",
    "    if len(parts) != 4:\n",
    "        return {}\n",
    "    \n",
    "    span_A_str, category_aspect, sentiment_str, span_B_str = parts\n",
    "\n",
    "    def parse_span(span_str):\n",
    "        if span_str == '-1,-1':\n",
    "            return (-1, -1)\n",
    "        try:\n",
    "            start, end = map(int, span_str.split(','))\n",
    "            return (start, end)\n",
    "        except ValueError:\n",
    "            return (-1, -1)\n",
    "\n",
    "    span_A = parse_span(span_A_str)\n",
    "    span_B = parse_span(span_B_str)\n",
    "    \n",
    "    try:\n",
    "        sentiment = int(sentiment_str)\n",
    "    except ValueError:\n",
    "        sentiment = -1 \n",
    "\n",
    "    return {\n",
    "        'span_A': span_A,\n",
    "        'span_B': span_B,\n",
    "        'category_aspect': category_aspect,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "\n",
    "def apply_deep_parsing(raw_quadruples_list):\n",
    "    return [parse_target_quadruples(q) for q in raw_quadruples_list]\n",
    "\n",
    "def parse_full_line(full_line_string):\n",
    "    parts = full_line_string.split('\\t', 1) \n",
    "    if len(parts) != 2:\n",
    "        return full_line_string.strip(), []\n",
    "\n",
    "    review_text = parts[0].strip()\n",
    "    target_string_raw = parts[1].strip()\n",
    "    \n",
    "    # Pulizia residui numerici a fine riga\n",
    "    target_string_clean = re.sub(r'[\\r\\n\\s]\\d+$', '', target_string_raw).strip()\n",
    "    raw_quadruples_list = [q.strip() for q in target_string_clean.split('\\t') if q.strip()]\n",
    "\n",
    "    return review_text, raw_quadruples_list\n",
    "\n",
    "def apply_full_parsing_pipeline(df):\n",
    "    \"\"\"\n",
    "    Applica la pipeline di parsing restituendo un nuovo DataFrame processato.\n",
    "    \"\"\"\n",
    "    df_res = df.copy() \n",
    "    \n",
    "    # Passaggio 1: Split testo e liste di stringhe target\n",
    "    parsed_lines = df_res['full_line_data'].apply(parse_full_line)\n",
    "    df_res['review_text'] = parsed_lines.apply(lambda x: x[0])\n",
    "    df_res['raw_quadruples_list'] = parsed_lines.apply(lambda x: x[1])\n",
    "    \n",
    "    # Passaggio 2: Decodifica delle quadruple in dizionari\n",
    "    df_res['parsed_quadruples'] = df_res['raw_quadruples_list'].apply(apply_deep_parsing)\n",
    "    \n",
    "    # Pulizia colonne temporanee e originali\n",
    "    return df_res.drop(columns=['full_line_data', 'raw_quadruples_list'])\n",
    "\n",
    "\n",
    "# --- II. ESECUZIONE CON COPIA DEI DATASET ---\n",
    "\n",
    "print(\"Creazione delle copie e avvio del parsing...\")\n",
    "\n",
    "# 1. Creazione delle copie dedicate al parsing\n",
    "df_train_parsing_laptop = df_train_laptop.copy()\n",
    "df_dev_parsing_laptop = df_dev_laptop.copy()\n",
    "df_test_parsing_laptop = df_test_laptop.copy()\n",
    "\n",
    "df_train_parsing_rest = df_train_rest.copy()\n",
    "df_dev_parsing_rest = df_dev_rest.copy()\n",
    "df_test_parsing_rest = df_test_rest.copy()\n",
    "\n",
    "# 2. Applicazione della pipeline sulle nuove variabili\n",
    "df_train_parsing_laptop = apply_full_parsing_pipeline(df_train_parsing_laptop)\n",
    "df_dev_parsing_laptop = apply_full_parsing_pipeline(df_dev_parsing_laptop)\n",
    "df_test_parsing_laptop = apply_full_parsing_pipeline(df_test_parsing_laptop)\n",
    "\n",
    "df_train_parsing_rest = apply_full_parsing_pipeline(df_train_parsing_rest)\n",
    "df_dev_parsing_rest = apply_full_parsing_pipeline(df_dev_parsing_rest)\n",
    "df_test_parsing_rest = apply_full_parsing_pipeline(df_test_parsing_rest)\n",
    "\n",
    "print(\"Parsing completato con successo.\")\n",
    "\n",
    "# Definiamo il nome della cartella\n",
    "cartella_parsing = \"data_parsing\"\n",
    "\n",
    "# Creiamo la cartella se non esiste\n",
    "os.makedirs(cartella_parsing, exist_ok=True)\n",
    "\n",
    "print(f\"Salvataggio dei dataset parsati nella cartella '{cartella_parsing}'...\")\n",
    "\n",
    "# --- SALVATAGGIO LAPTOP ---\n",
    "df_train_parsing_laptop.to_pickle(os.path.join(cartella_parsing, \"train_laptop_parsed.pkl\"))\n",
    "df_dev_parsing_laptop.to_pickle(os.path.join(cartella_parsing, \"dev_laptop_parsed.pkl\"))\n",
    "df_test_parsing_laptop.to_pickle(os.path.join(cartella_parsing, \"test_laptop_parsed.pkl\"))\n",
    "print(\"Dataset Laptop salvati!\")\n",
    "\n",
    "# --- SALVATAGGIO RESTAURANT ---\n",
    "df_train_parsing_rest.to_pickle(os.path.join(cartella_parsing, \"train_rest_parsed.pkl\"))\n",
    "df_dev_parsing_rest.to_pickle(os.path.join(cartella_parsing, \"dev_rest_parsed.pkl\"))\n",
    "df_test_parsing_rest.to_pickle(os.path.join(cartella_parsing, \"test_rest_parsed.pkl\"))\n",
    "print(\"Dataset Restaurant salvati!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- III. VERIFICA FINALE ---\n",
    "\n",
    "print(\"\\nAnteprima del DataFrame di Test (df_test_parsing_laptop):\")\n",
    "display(df_test_parsing_laptop[['review_text', 'parsed_quadruples']].head())\n",
    "\n",
    "print(\"\\nAnteprima del DataFrame di Test (df_test_parsing_rest):\")\n",
    "display(df_test_parsing_rest[['review_text', 'parsed_quadruples']].head())\n",
    "\n",
    "# Controllo specifico richiesto (riga 3)\n",
    "print(f\"\\nQuadruple decodificate: {df_test_parsing_rest['parsed_quadruples'].loc[3]}\")\n",
    "print(f\"Testo corrispondente: {df_test_parsing_rest['review_text'].loc[3]}\")\n",
    "\n",
    "print(\"\\nDimensioni finali (Train, Dev, Test):\")\n",
    "print(df_train_parsing_laptop.shape, df_dev_parsing_laptop.shape, df_test_parsing_laptop.shape)\n",
    "print(df_train_parsing_rest.shape, df_dev_parsing_rest.shape, df_test_parsing_rest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd13dc4",
   "metadata": {},
   "source": [
    "## Sub-word Alignment & BIO Labeling\n",
    "\n",
    "### Pre-processing dei Dati: Tokenizzazione, Allineamento BIO e Identificazione degli Impliciti\n",
    "\n",
    "Questa cella esegue la preparazione fondamentale del dataset testuale per renderlo compatibile con l'architettura Multi-Task basata su ModernBERT. Il codice processa le quadruple originali e trasforma le parole in tensori numerici, risolvendo il problema dell'allineamento dei token e implementando la logica di estrazione avanzata del task ACOS. \n",
    "\n",
    "Nello specifico, la funzione `encode_and_align_labels` esegue le seguenti operazioni chiave:\n",
    "\n",
    "* **Tokenizzazione e Allineamento Sub-word:** Poiché i modelli BERT suddividono le parole in sotto-unità (sub-words), il codice riallinea le etichette originali ai nuovi token generati. Utilizza lo schema di tagging BIO (Begin-Inside-Outside) per mappare accuratamente le parole esplicite, assegnando `B-ASP`/`I-ASP` per gli aspetti e `B-OPI`/`I-OPI` per le opinioni.\n",
    "* **Gestione degli Elementi Impliciti (Il Core del Task ACOS):** Le recensioni dei prodotti contengono una grande quantità di aspetti e opinioni implicite. Per gestire questi casi, se un elemento non è esplicitamente espresso nel testo, viene descritto con il valore NULL (rappresentato dalle coordinate `-1, -1` nel nostro dataset).\n",
    "* **Creazione delle Etichette Binarie:** Quando il sistema rileva coordinate `(-1, -1)`, accende due flag binari (`has_implicit_aspect` e `has_implicit_opinion`). Queste etichette extra verranno fornite al modello in fase di addestramento per addestrare i due classificatori binari posizionati sul token `[CLS]`, permettendo alla rete di prevedere la presenza di aspetti o opinioni implicite.\n",
    "* **Salvataggio Seriale:** Infine, i dati processati e allineati per entrambi i domini (Laptop e Restaurant) vengono salvati in formato `.pkl` all'interno della cartella `data_allineati`, pronti per essere caricati in modo efficiente dai DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04564fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allineamento in corso per lo split: TRAIN_LAPTOP...\n",
      "Allineamento in corso per lo split: DEV_LAPTOP...\n",
      "Allineamento in corso per lo split: TEST_LAPTOP...\n",
      "Allineamento in corso per lo split: TRAIN_RESTAURANT...\n",
      "Allineamento in corso per lo split: DEV_RESTAURANT...\n",
      "Allineamento in corso per lo split: TEST_RESTAURANT...\n",
      "\n",
      "==================================================\n",
      "VISUALIZZAZIONE DEI DATASET ALLINEATI\n",
      "\n",
      "--- PRIME RIGHE TRAIN LAPTOP---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace ##r wants $ 170 to just look at it then ad...</td>\n",
       "      <td>[50281, 584, 817, 83, 88, 1103, 5, 15046, 936,...</td>\n",
       "      <td>[0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update : i repaired it myself for $ 12 .</td>\n",
       "      <td>[50281, 11183, 27, 74, 4762, 12260, 262, 17089...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i had nothing to lose since it was a paper wei...</td>\n",
       "      <td>[50281, 74, 10178, 26142, 936, 77, 583, 17480,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the shame of it is knowing it took me 15 minut...</td>\n",
       "      <td>[50281, 783, 1200, 482, 1171, 262, 261, 14428,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first one that they shipped was obviously defe...</td>\n",
       "      <td>[50281, 7053, 531, 3529, 9328, 1200, 6390, 423...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  ace ##r wants $ 170 to just look at it then ad...   \n",
       "1           update : i repaired it myself for $ 12 .   \n",
       "2  i had nothing to lose since it was a paper wei...   \n",
       "3  the shame of it is knowing it took me 15 minut...   \n",
       "4  first one that they shipped was obviously defe...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 584, 817, 83, 88, 1103, 5, 15046, 936,...   \n",
       "1  [50281, 11183, 27, 74, 4762, 12260, 262, 17089...   \n",
       "2  [50281, 74, 10178, 26142, 936, 77, 583, 17480,...   \n",
       "3  [50281, 783, 1200, 482, 1171, 262, 261, 14428,...   \n",
       "4  [50281, 7053, 531, 3529, 9328, 1200, 6390, 423...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE DEV LAPTOP ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this unit is ` ` pretty ` ` and st ##yl ##ish ...</td>\n",
       "      <td>[50281, 2520, 8522, 261, 65, 65, 38256, 65, 65...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for now i ' m okay with up ##ping the experien...</td>\n",
       "      <td>[50281, 1542, 2666, 74, 8, 78, 536, 333, 3113,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seems unlikely but whatever , i ' ll go with it .</td>\n",
       "      <td>[50281, 339, 3030, 328, 10355, 2858, 38499, 13...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this version has been my least favorite versio...</td>\n",
       "      <td>[50281, 2520, 4149, 7110, 20394, 2577, 38462, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 4, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- biggest disappointment is the track pad .</td>\n",
       "      <td>[50281, 14, 2760, 3219, 3431, 9626, 420, 261, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 0, 0, 1, 2, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  this unit is ` ` pretty ` ` and st ##yl ##ish ...   \n",
       "1  for now i ' m okay with up ##ping the experien...   \n",
       "2  seems unlikely but whatever , i ' ll go with it .   \n",
       "3  this version has been my least favorite versio...   \n",
       "4        - biggest disappointment is the track pad .   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 2520, 8522, 261, 65, 65, 38256, 65, 65...   \n",
       "1  [50281, 1542, 2666, 74, 8, 78, 536, 333, 3113,...   \n",
       "2  [50281, 339, 3030, 328, 10355, 2858, 38499, 13...   \n",
       "3  [50281, 2520, 4149, 7110, 20394, 2577, 38462, ...   \n",
       "4  [50281, 14, 2760, 3219, 3431, 9626, 420, 261, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 4, 4, 4, 4, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 3, 4, 4, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 3, 4, 4, 0, 0, 1, 2, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TEST LAPTOP ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the unit cost $ 275 to start with , so it is n...</td>\n",
       "      <td>[50281, 783, 8522, 16736, 5, 20450, 936, 5478,...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going from ace ##r 15 to ace ##r 11 was diffic...</td>\n",
       "      <td>[50281, 5681, 4064, 584, 817, 83, 1010, 936, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also it ' s not a true ss ##d drive in there b...</td>\n",
       "      <td>[50281, 12563, 262, 8, 84, 1439, 66, 5672, 859...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the computer has difficulty switching between ...</td>\n",
       "      <td>[50281, 783, 32948, 7110, 38157, 90, 16065, 27...</td>\n",
       "      <td>[0, 0, 1, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 / 28 / 18 - a couple days ago i updated the ...</td>\n",
       "      <td>[50281, 19, 16, 1619, 16, 1093, 14, 66, 20313,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  the unit cost $ 275 to start with , so it is n...   \n",
       "1  going from ace ##r 15 to ace ##r 11 was diffic...   \n",
       "2  also it ' s not a true ss ##d drive in there b...   \n",
       "3  the computer has difficulty switching between ...   \n",
       "4  2 / 28 / 18 - a couple days ago i updated the ...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 783, 8522, 16736, 5, 20450, 936, 5478,...   \n",
       "1  [50281, 5681, 4064, 584, 817, 83, 1010, 936, 5...   \n",
       "2  [50281, 12563, 262, 8, 84, 1439, 66, 5672, 859...   \n",
       "3  [50281, 783, 32948, 7110, 38157, 90, 16065, 27...   \n",
       "4  [50281, 19, 16, 1619, 16, 1093, 14, 66, 20313,...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 3, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, ...  \n",
       "3  [0, 0, 1, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TRAIN RESTAURANT---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>[50281, 6881, 3390, 4064, 35065, 28361, 2520, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we , there were four of us , arrived at noon -...</td>\n",
       "      <td>[50281, 664, 13, 9088, 12796, 12496, 1171, 316...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they never brought us compliment ##ary noodles...</td>\n",
       "      <td>[50281, 9328, 7594, 1288, 1224, 316, 21013, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the food was lou ##sy - too sweet or too salty...</td>\n",
       "      <td>[50281, 783, 19480, 4238, 77, 276, 817, 19089,...</td>\n",
       "      <td>[0, 0, 1, 0, 3, 4, 4, 4, 0, 3, 4, 0, 3, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after all that , they complained to me about t...</td>\n",
       "      <td>[50281, 6438, 455, 3529, 13, 9328, 21013, 1243...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  judging from previous posts this used to be a ...   \n",
       "1  we , there were four of us , arrived at noon -...   \n",
       "2  they never brought us compliment ##ary noodles...   \n",
       "3  the food was lou ##sy - too sweet or too salty...   \n",
       "4  after all that , they complained to me about t...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 6881, 3390, 4064, 35065, 28361, 2520, ...   \n",
       "1  [50281, 664, 13, 9088, 12796, 12496, 1171, 316...   \n",
       "2  [50281, 9328, 7594, 1288, 1224, 316, 21013, 20...   \n",
       "3  [50281, 783, 19480, 4238, 77, 276, 817, 19089,...   \n",
       "4  [50281, 6438, 455, 3529, 13, 9328, 21013, 1243...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 1, 0, 3, 4, 4, 4, 0, 3, 4, 0, 3, 4, 4, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE DEV RESTAURANT ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca n ' t wait wait for my next visit .</td>\n",
       "      <td>[50281, 6357, 79, 8, 85, 14061, 14061, 1542, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their sake list was extensive , but we were lo...</td>\n",
       "      <td>[50281, 14094, 84, 640, 3550, 4238, 2068, 3134...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the spicy tuna roll was unusually good and the...</td>\n",
       "      <td>[50281, 783, 1033, 2576, 85, 9821, 1811, 4238,...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 3, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we love th pink pony .</td>\n",
       "      <td>[50281, 664, 26617, 394, 49723, 81, 2421, 15, ...</td>\n",
       "      <td>[0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this place has got to be the best japanese res...</td>\n",
       "      <td>[50281, 2520, 5070, 7110, 19559, 936, 1257, 78...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0             ca n ' t wait wait for my next visit .   \n",
       "1  their sake list was extensive , but we were lo...   \n",
       "2  the spicy tuna roll was unusually good and the...   \n",
       "3                             we love th pink pony .   \n",
       "4  this place has got to be the best japanese res...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 6357, 79, 8, 85, 14061, 14061, 1542, 2...   \n",
       "1  [50281, 14094, 84, 640, 3550, 4238, 2068, 3134...   \n",
       "2  [50281, 783, 1033, 2576, 85, 9821, 1811, 4238,...   \n",
       "3  [50281, 664, 26617, 394, 49723, 81, 2421, 15, ...   \n",
       "4  [50281, 2520, 5070, 7110, 19559, 936, 1257, 78...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 1, 2, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 3, 0, 0, 1, 2, ...  \n",
       "3  [0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TEST RESTAURANT ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yu ##m !</td>\n",
       "      <td>[50281, 30838, 817, 78, 2, 50282, 50283, 50283...</td>\n",
       "      <td>[0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serves really good su ##shi .</td>\n",
       "      <td>[50281, 1498, 265, 28235, 12311, 3467, 817, 41...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the biggest portions but adequate .</td>\n",
       "      <td>[50281, 1439, 783, 2760, 3219, 631, 621, 2858,...</td>\n",
       "      <td>[0, 3, 4, 4, 4, 1, 2, 0, 3, 4, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green tea cr ##eme br ##ule ##e is a must !</td>\n",
       "      <td>[50281, 11707, 442, 66, 7083, 817, 20867, 1288...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it has great su ##shi and even better service .</td>\n",
       "      <td>[50281, 262, 7110, 17124, 3467, 817, 41386, 39...</td>\n",
       "      <td>[0, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_text  \\\n",
       "0                                         yu ##m !   \n",
       "1                    serves really good su ##shi .   \n",
       "2          not the biggest portions but adequate .   \n",
       "3      green tea cr ##eme br ##ule ##e is a must !   \n",
       "4  it has great su ##shi and even better service .   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 30838, 817, 78, 2, 50282, 50283, 50283...   \n",
       "1  [50281, 1498, 265, 28235, 12311, 3467, 817, 41...   \n",
       "2  [50281, 1439, 783, 2760, 3219, 631, 621, 2858,...   \n",
       "3  [50281, 11707, 442, 66, 7083, 817, 20867, 1288...   \n",
       "4  [50281, 262, 7110, 17124, 3467, 817, 41386, 39...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 3, 4, 4, 4, 1, 2, 0, 3, 4, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, ...  \n",
       "4  [0, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvataggio dei dataset nella cartella 'data_allineati' in formato Pickle...\n",
      "✅ Salvataggio completato con successo! Dati pronti per il training.\n"
     ]
    }
   ],
   "source": [
    "# 1. Caricamento del Tokenizer di ModernBERT\n",
    "tokenizer_name = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def encode_and_align_labels(words, parsed_quadruples, tokenizer, max_len=128):\n",
    "    tokenized_input = tokenizer(\n",
    "        words, truncation=True, max_length=max_len,\n",
    "        padding='max_length', is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = [\"O\"] * max_len\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    \n",
    "    # --- GESTIONE IMPLICITI ---\n",
    "    has_implicit_aspect = 0\n",
    "    has_implicit_opinion = 0\n",
    "    \n",
    "    for quad in parsed_quadruples:\n",
    "        asp_span = quad.get('span_A', (-1, -1))\n",
    "        opi_span = quad.get('span_B', (-1, -1))\n",
    "        \n",
    "        # Se troviamo le coordinate (-1, -1), accendiamo la spia dell'implicito!\n",
    "        if asp_span == (-1, -1) or asp_span == [-1, -1]:\n",
    "            has_implicit_aspect = 1\n",
    "        if opi_span == (-1, -1) or opi_span == [-1, -1]:\n",
    "            has_implicit_opinion = 1\n",
    "            \n",
    "        def align_span(span, b_tag, i_tag):\n",
    "            if span == (-1, -1) or span == [-1, -1]:\n",
    "                return\n",
    "            \n",
    "            start_word_idx, end_word_idx = span\n",
    "            span_started = False\n",
    "            \n",
    "            for i, word_id in enumerate(word_ids):\n",
    "                if i >= max_len or word_id is None:\n",
    "                    continue\n",
    "                if start_word_idx <= word_id < end_word_idx:\n",
    "                    if not span_started:\n",
    "                        labels[i] = b_tag\n",
    "                        span_started = True\n",
    "                    else:\n",
    "                        labels[i] = i_tag\n",
    "\n",
    "        align_span(asp_span, \"B-ASP\", \"I-ASP\")\n",
    "        align_span(opi_span, \"B-OPI\", \"I-OPI\")\n",
    "\n",
    "    label_map = {\"O\": 0, \"B-ASP\": 1, \"I-ASP\": 2, \"B-OPI\": 3, \"I-OPI\": 4}\n",
    "    label_ids = [label_map[l] for l in labels]\n",
    "\n",
    "    return {\n",
    "        'input_ids': tokenized_input['input_ids'],\n",
    "        'attention_mask': tokenized_input['attention_mask'],\n",
    "        'labels': label_ids,\n",
    "        'implicit_aspect_label': has_implicit_aspect, \n",
    "        'implicit_opinion_label': has_implicit_opinion \n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "def process_align_dataset(df, tokenizer, split_name):\n",
    "    \"\"\"\n",
    "    Applica l'allineamento e aggiunge le colonne input_ids, attention_mask e labels.\n",
    "    \"\"\"\n",
    "    print(f\"Allineamento in corso per lo split: {split_name}...\")\n",
    "    \n",
    "    # Applichiamo la funzione riga per riga\n",
    "    # Usiamo .split() perché il testo è pre-tokenizzato nel dataset originale\n",
    "    processed_series = df.apply(\n",
    "        lambda row: encode_and_align_labels(\n",
    "            row['review_text'].split(), \n",
    "            row['parsed_quadruples'], \n",
    "            tokenizer, \n",
    "            max_len=128\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Convertiamo la lista di dizionari in un DataFrame e lo concateniamo\n",
    "    df_result = pd.DataFrame(processed_series.tolist(), index=df.index)\n",
    "    return pd.concat([df, df_result], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. CREAZIONE DELLE COPIE DEI DATASET ---\n",
    "# Creiamo copie profonde per evitare di modificare i DataFrame originali\n",
    "df_train_align_laptop = df_train_parsing_laptop.copy()\n",
    "df_dev_align_laptop = df_dev_parsing_laptop.copy()\n",
    "df_test_align_laptop = df_test_parsing_laptop.copy()\n",
    "\n",
    "df_train_align_rest = df_train_parsing_rest.copy()\n",
    "df_dev_align_rest = df_dev_parsing_rest.copy()\n",
    "df_test_align_rest = df_test_parsing_rest.copy()\n",
    "\n",
    "# --- 2. ESECUZIONE DELL'ALLINEAMENTO ---\n",
    "df_train_align_laptop = process_align_dataset(df_train_align_laptop, tokenizer, \"TRAIN_LAPTOP\")\n",
    "df_dev_align_laptop = process_align_dataset(df_dev_align_laptop, tokenizer, \"DEV_LAPTOP\")\n",
    "df_test_align_laptop = process_align_dataset(df_test_align_laptop, tokenizer, \"TEST_LAPTOP\")\n",
    "\n",
    "df_train_align_rest = process_align_dataset(df_train_align_rest, tokenizer, \"TRAIN_RESTAURANT\")\n",
    "df_dev_align_rest = process_align_dataset(df_dev_align_rest, tokenizer, \"DEV_RESTAURANT\")\n",
    "df_test_align_rest = process_align_dataset(df_test_align_rest, tokenizer, \"TEST_RESTAURANT\")\n",
    "\n",
    "# --- 3. OUTPUT DELLE PRIME RIGHE ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VISUALIZZAZIONE DEI DATASET ALLINEATI\")\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TRAIN LAPTOP---\")\n",
    "display(df_train_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE DEV LAPTOP ---\")\n",
    "display(df_dev_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TEST LAPTOP ---\")\n",
    "display(df_test_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TRAIN RESTAURANT---\")\n",
    "display(df_train_align_rest[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE DEV RESTAURANT ---\")\n",
    "display(df_dev_align_rest[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TEST RESTAURANT ---\")\n",
    "display(df_test_align_rest[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "# --- 4. SALVATAGGIO DEI DATASET NELLA CARTELLA \"data_allineati\" ---\n",
    "# Creiamo la cartella se non esiste già\n",
    "output_dir = \"data_allineati\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nSalvataggio dei dataset nella cartella '{output_dir}' in formato Pickle...\")\n",
    "\n",
    "# Salviamo i dataset dei Laptop\n",
    "df_train_align_laptop.to_pickle(os.path.join(output_dir, \"train_laptop_aligned.pkl\"))\n",
    "df_dev_align_laptop.to_pickle(os.path.join(output_dir, \"dev_laptop_aligned.pkl\"))\n",
    "df_test_align_laptop.to_pickle(os.path.join(output_dir, \"test_laptop_aligned.pkl\"))\n",
    "\n",
    "# Salviamo i dataset dei Restaurant\n",
    "df_train_align_rest.to_pickle(os.path.join(output_dir, \"train_rest_aligned.pkl\"))\n",
    "df_dev_align_rest.to_pickle(os.path.join(output_dir, \"dev_rest_aligned.pkl\"))\n",
    "df_test_align_rest.to_pickle(os.path.join(output_dir, \"test_rest_aligned.pkl\"))\n",
    "\n",
    "print(\"✅ Salvataggio completato con successo! Dati pronti per il training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df3a5e",
   "metadata": {},
   "source": [
    "### Data Preparation & Offset Fix ( Category & Sentiment)\n",
    "\n",
    "Per replicare l'approccio *Multiple Multi-class Classification* del paper, il codice è diviso in tre funzioni modulari:\n",
    "\n",
    "1. **Creazione del Vocabolario (`build_category_vocab`)**: \n",
    "   Scansiona tutti i set di dati (Train, Dev, Test) per estrarre l'elenco completo delle categorie uniche del dominio. Le ordina alfabeticamente per garantire che l'indice assegnato a ciascuna categoria (es. `DISPLAY#QUALITY` -> Indice 24) sia identico e immutabile in tutta la pipeline.\n",
    "\n",
    "2. **Prodotto Cartesiano e Labels (`prepare_pairs_dataset`)**:\n",
    "   * **Prodotto Cartesiano**: Per ogni frase, crea tutte le combinazioni possibili tra gli aspetti e le opinioni presenti.\n",
    "   * **Fix Offset `[CLS]`**: Applica automaticamente un correttivo matematico (`+1`) agli indici salvati per allinearli al token speciale `[CLS]` che ModernBERT aggiungerà in fase di addestramento. Questo garantisce che gli span puntino sempre alle parole corrette.\n",
    "   * **Vettorizzazione Multi-Classe**: Per ogni coppia creata, genera un array lungo quanto il numero di categorie (es. 121 per Laptop), inizializzato interamente a `3` (Classe *Invalid*). Se la coppia corrisponde a una quadrupla d'oro, sovrascrive il `3` con il sentiment corretto (`0=Pos`, `1=Neg`, `2=Neu`) all'indice della categoria corrispondente.\n",
    "\n",
    "3. **`process_and_save_domain`**:\n",
    "   Una funzione che automatizza l'intera pipeline per un dominio specifico (Laptop o Restaurant) e salva i nuovi dataset strutturati (e la lista delle categorie) all'interno della cartella `data_coppie` in formato `.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81114f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- 1. FUNZIONE PER CREARE IL VOCABOLARIO DELLE CATEGORIE ---\n",
    "def build_category_vocab(df_list):\n",
    "    \"\"\"\n",
    "    Estrae tutte le categorie uniche da una lista di dataframe e le ordina.\n",
    "    Ritorna la lista delle categorie e il dizionario {categoria: id}.\n",
    "    \"\"\"\n",
    "    all_categories = set()\n",
    "    for df in df_list:\n",
    "        for quads in df['parsed_quadruples']:\n",
    "            for q in quads:\n",
    "                all_categories.add(q['category_aspect'])\n",
    "                \n",
    "    category_list = sorted(list(all_categories))\n",
    "    category2id = {c: idx for idx, c in enumerate(category_list)}\n",
    "    \n",
    "    return category_list, category2id\n",
    "\n",
    "\n",
    "# --- 2. FUNZIONE PER IL PRODOTTO CARTESIANO E LE LABELS (AGGIORNATA PER SOTA) ---\n",
    "def prepare_pairs_dataset(df, category_list, category2id, invalid_class=3):\n",
    "    \"\"\"\n",
    "    Crea le coppie candidate per ogni frase.\n",
    "    NOVITÀ: Introduce l'Hard Negative Sampling per gli impliciti.\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['review_text']\n",
    "        quads = row['parsed_quadruples']\n",
    "        \n",
    "        aspect_spans = set()\n",
    "        opinion_spans = set()\n",
    "        \n",
    "        # 🔥 IL SEGRETO PER SUPERARE IL PAPER: HARD NEGATIVE SAMPLING 🔥\n",
    "        # Aggiungiamo forzatamente le coordinate implicite a TUTTE le frasi.\n",
    "        # Così il modello impara a dire \"NO\" (Classe 3) quando incrocia un\n",
    "        # implicito dove non dovrebbe esserci!\n",
    "        aspect_spans.add((-1, -1))\n",
    "        opinion_spans.add((-1, -1))\n",
    "        \n",
    "        for q in quads:\n",
    "            aspect_spans.add(tuple(q.get('span_A', (-1, -1))))\n",
    "            opinion_spans.add(tuple(q.get('span_B', (-1, -1))))\n",
    "            \n",
    "        for a_span in aspect_spans:\n",
    "            for o_span in opinion_spans:\n",
    "                \n",
    "                # Fix Offset +1 per il token [CLS]\n",
    "                fixed_a = (a_span[0] + 1 if a_span[0] != -1 else -1, \n",
    "                           a_span[1] + 1 if a_span[1] != -1 else -1)\n",
    "                \n",
    "                fixed_o = (o_span[0] + 1 if o_span[0] != -1 else -1, \n",
    "                           o_span[1] + 1 if o_span[1] != -1 else -1)\n",
    "\n",
    "                labels_array = [invalid_class] * len(category_list)\n",
    "                is_valid = False\n",
    "                \n",
    "                for q in quads:\n",
    "                    if tuple(q.get('span_A', (-1, -1))) == a_span and tuple(q.get('span_B', (-1, -1))) == o_span:\n",
    "                        cat_id = category2id[q['category_aspect']] \n",
    "                        sent_id = int(q['sentiment'])              \n",
    "                        labels_array[cat_id] = sent_id\n",
    "                        is_valid = True\n",
    "                \n",
    "                # Evitiamo di creare (NULL, NULL) finti per non inquinare troppo i dati\n",
    "                if not is_valid and a_span == (-1, -1) and o_span == (-1, -1):\n",
    "                    continue\n",
    "                \n",
    "                new_data.append({\n",
    "                    'review_text': text,\n",
    "                    'aspect_span': fixed_a,     \n",
    "                    'opinion_span': fixed_o,    \n",
    "                    'labels': labels_array       \n",
    "                })\n",
    "                \n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "# --- 3. FUNZIONE MASTER ---\n",
    "def process_and_save_domain(domain_name, df_train, df_dev, df_test, output_dir=\"data_coppie\"):\n",
    "    \"\"\"\n",
    "    Esegue l'intera pipeline per un dominio specifico e salva i file su disco.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAvvio pipeline per il dominio: {domain_name.upper()}...\")\n",
    "    \n",
    "    # 1. Troviamo le categorie\n",
    "    category_list, category2id = build_category_vocab([df_train, df_dev, df_test])\n",
    "    print(f\"Trovate {len(category_list)} categorie uniche.\")\n",
    "    \n",
    "    # 2. Creiamo i dataframe delle coppie\n",
    "    print(f\"Generazione dei dataset di Coppie in corso...\")\n",
    "    df_train_pairs = prepare_pairs_dataset(df_train, category_list, category2id)\n",
    "    df_dev_pairs = prepare_pairs_dataset(df_dev, category_list, category2id)\n",
    "    df_test_pairs = prepare_pairs_dataset(df_test, category_list, category2id)\n",
    "    \n",
    "    # 3. Salvataggio\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    df_train_pairs.to_pickle(os.path.join(output_dir, f\"train_{domain_name}_pairs.pkl\"))\n",
    "    df_dev_pairs.to_pickle(os.path.join(output_dir, f\"dev_{domain_name}_pairs.pkl\"))\n",
    "    df_test_pairs.to_pickle(os.path.join(output_dir, f\"test_{domain_name}_pairs.pkl\"))\n",
    "    \n",
    "    with open(os.path.join(output_dir, f\"{domain_name}_categories.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(category_list, f)\n",
    "        \n",
    "    print(f\"Dati per '{domain_name}' salvati in '{output_dir}'! Esempi nel Train: {len(df_train_pairs)}\")\n",
    "    return df_train_pairs, df_dev_pairs, df_test_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf34a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avvio pipeline per il dominio: LAPTOP...\n",
      "Trovate 121 categorie uniche.\n",
      "Generazione dei dataset di Coppie in corso...\n",
      "Dati per 'laptop' salvati in 'data_coppie'! Esempi nel Train: 9247\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>aspect_span</th>\n",
       "      <th>opinion_span</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace ##r wants $ 170 to just look at it then ad...</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(-1, -1)</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update : i repaired it myself for $ 12 .</td>\n",
       "      <td>(-1, -1)</td>\n",
       "      <td>(-1, -1)</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text aspect_span opinion_span  \\\n",
       "0  ace ##r wants $ 170 to just look at it then ad...      (1, 3)     (-1, -1)   \n",
       "1           update : i repaired it myself for $ 12 .    (-1, -1)     (-1, -1)   \n",
       "\n",
       "                                              labels  \n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avvio pipeline per il dominio: RESTAURANT...\n",
      "Trovate 13 categorie uniche.\n",
      "Generazione dei dataset di Coppie in corso...\n",
      "Dati per 'restaurant' salvati in 'data_coppie'! Esempi nel Train: 6366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>aspect_span</th>\n",
       "      <th>opinion_span</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>(14, 17)</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>(11, 12)</td>\n",
       "      <td>(-1, -1)</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text aspect_span opinion_span  \\\n",
       "0  judging from previous posts this used to be a ...    (11, 12)     (14, 17)   \n",
       "1  judging from previous posts this used to be a ...    (11, 12)     (-1, -1)   \n",
       "\n",
       "                                    labels  \n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3]  \n",
       "1  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lanciamo per il Laptop\n",
    "train_lap, dev_lap, test_lap = process_and_save_domain(\"laptop\", df_train_parsing_laptop, df_dev_parsing_laptop, df_test_parsing_laptop)\n",
    "display(train_lap.head(2))\n",
    "\n",
    "# Lanciamo per il Restaurant\n",
    "train_rest, dev_rest, test_rest = process_and_save_domain(\"restaurant\", df_train_parsing_rest, df_dev_parsing_rest, df_test_parsing_rest)\n",
    "display(train_rest.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
