{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fc04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate.\n"
     ]
    }
   ],
   "source": [
    "# Import delle librerie necessarie\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "print(\"Librerie caricate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70bed1",
   "metadata": {},
   "source": [
    "### Impostazioni per la riproducibilità "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68aa33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seeds impostati su 42.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Imposto i seed per la riproducibilità.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        # Imposto anche i seed per la GPU, se disponibile\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# Esegui l'impostazione del seed\n",
    "set_seed(42) \n",
    "print(\"Random seeds impostati su 42.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c52222",
   "metadata": {},
   "source": [
    "### Configurazione Iniziale degli Hyperparameters (W&B)\n",
    "\n",
    "Questa sezione definisce i principali parametri di addestramento (*hyperparameters*) per il *fine-tuning* del modello **ModernBERT**, registrandoli in **Weights & Biases** per tracciabilità e riproducibilità.\n",
    "\n",
    "| Parametro | Valore | Motivazione della Scelta |\n",
    "| :--- | :--- | :--- |\n",
    "| **`learning_rate`** | `5e-5` (0.00005) | È il tasso di apprendimento *default* consigliato da Google/Hugging Face per il *fine-tuning* dei modelli BERT/RoBERTa. È un valore conservativo che assicura che il modello si adatti al nuovo *task* (ACOS) senza \"dimenticare\" le conoscenze acquisite nel *pre-training*. |\n",
    "| **`epochs`** | `5` | Un valore tipico e contenuto per il *fine-tuning* di modelli Transformer. Di solito, 3 o 4 *epochs* sono sufficienti per convergere, ma 5 offrono un buon equilibrio tra addestramento e prevenzione dell'overfitting sui dataset di dimensioni limitate come ACOS. |\n",
    "| **`batch_size`** | `16` | Questa dimensione del *batch* è comune quando si lavora con modelli grandi come RoBERTa-base, bilanciando la stabilità dell'addestramento con le limitazioni della **memoria GPU**. |\n",
    "| **`model_name`** | `answerdotai/ModernBERT-base` | Scegliamo questo modello specifico Encoder-only come \"ModernBERT\" per le prestazioni superiori e un pre-training più robusto rispetto al BERTbase originale |\n",
    "| **`dataset`** | `Laptop-ACOS` | Identifica il sotto-dataset specifico utilizzato per questo esperimento. |\n",
    "| **`seed`** | `42` | Il **seed di riproducibilità**, fissato a 42 (la convenzione standard ML), garantisce che ogni volta che lo *script* viene eseguito, l'inizializzazione dei pesi e lo *shuffling* dei dati siano identici, garantendo la tracciabilità scientifica dei risultati. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb63eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristinatomaciello2001\u001b[0m (\u001b[33mcristinatextmining\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cristinatomaciello/Desktop/Università/2anno/1semstre/big data/progetto-text-mining/wandb/run-20251121_170232-iopuquml</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/iopuquml' target=\"_blank\">run_answerdotai/ModernBERT-base_Laptop-ACOS</a></strong> to <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/iopuquml' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/iopuquml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B inizializzato per il progetto: BigData-TextMining-ACOS\n"
     ]
    }
   ],
   "source": [
    "WANDB_ENTITY = \"cristinatextmining\"\n",
    "\n",
    "# 1. Definizione degli Hyperparameters\n",
    "config = {\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 16,\n",
    "    \"model_name\": \"answerdotai/ModernBERT-base\",\n",
    "    \"dataset\": \"Laptop-ACOS\",\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# 2. Inizializzazione del Run\n",
    "wandb.init(\n",
    "    project=\"BigData-TextMining-ACOS\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    config=config,\n",
    "    name=f\"run_{config['model_name']}_{config['dataset']}\"\n",
    ")\n",
    "\n",
    "print(f\"W&B inizializzato per il progetto: {wandb.run.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a0a15",
   "metadata": {},
   "source": [
    "### Caricamento dei 3 dataset LAPTOP-ACOS\n",
    "Questa cella è dedicata al caricamento dei dataset TSV di ACOS (Training, Development e Test) dalla directory locale.\n",
    "\n",
    "Data la struttura complessa del file di annotazione, che contiene tabulazioni (\\t) interne e un numero variabile di quadruple per riga, la funzione load_as_single_string adotta una strategia di caricamento flessibile:\n",
    "\n",
    "1. **Forzatura Stringa Unica:** Viene utilizzato un separatore inesistente (\\x07) per istruire Pandas a caricare l'intera riga TSV come una singola colonna stringa *(full_line_data).*\n",
    "\n",
    "2. **Robustezza:** Questo approccio previene i comuni ParserError causati da tabulazioni o delimitatori sporchi interni, garantendo che i dati grezzi vengano letti completamente senza perdita.\n",
    "\n",
    "L'output di questa cella sono i tre DataFrame *(df_train, df_dev, df_test)*, ciascuno pronto per il parsing sequenziale sul contenuto della colonna full_line_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28042a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File laptop_train_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_dev_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_test_quad_bert.tsv caricato come 1 colonna unica.\n",
      "Caricamento Flessibile Completato.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                               full_line_data\\n0                                                                                                 ace ##r wants $ 170 to just look at it then add the repair cost on top of that .\\\\t0,2 SUPPORT#PRICE 1 -1,-1\\n1                                                                                                                                      update : i repaired it myself for $ 12 .\\\\t-1,-1 LAPTOP#GENERAL 1 -1,-1\\n2                                                                                                                 i had nothing to lose since it was a paper weight otherwise .\\\\t-1,-1 LAPTOP#GENERAL 0 -1,-1\\n3                                               the shame of it is knowing it took me 15 minutes and $ 12 to fix it and ace ##r wanted to rob me of $ 170 just to look at it .\\\\t18,20 SUPPORT#GENERAL 0 -1,-1\\n4  first one that they shipped was obviously defective , super slow and speakers were ga ##rb ##led .\\\\t-1,-1 SHIPPING#GENERAL 0 7,8\\\\t-1,-1 SHIPPING#GENERAL 0 10,11\\\\t12,13 MULTIMEDIA_DEVICES#GENERAL 0 14,17'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Definisci il percorso base della cartella dei dati\n",
    "DATA_DIR = 'data/Laptop-ACOS/'\n",
    "\n",
    "# Definisci i percorsi completi dei file\n",
    "TRAIN_FILE_PATH = os.path.join(DATA_DIR, 'laptop_train_quad_bert.tsv')\n",
    "DEV_FILE_PATH = os.path.join(DATA_DIR, 'laptop_dev_quad_bert.tsv')\n",
    "TEST_FILE_PATH = os.path.join(DATA_DIR, 'laptop_test_quad_bert.tsv')\n",
    "\n",
    "def load_as_single_string(path):\n",
    "    \"\"\"\n",
    "    Carica l'intero file TSV in un'unica colonna stringa, forzando la lettura riga per riga, \n",
    "    per evitare errori di parsing dovuti a delimitatori interni.\n",
    "    \"\"\"\n",
    "    # 1. Utilizza read_csv ma forza l'uso di un separatore inesistente e non usare header\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        sep='\\x07', # Separa per un carattere inesistente (Bell character)\n",
    "        header=None, \n",
    "        on_bad_lines='skip', # Ignora le righe che danno problemi di formattazione\n",
    "        engine='python'\n",
    "    )\n",
    "    \n",
    "    # Rinomina l'unica colonna che contiene l'intera riga TSV\n",
    "    df.columns = ['full_line_data']    \n",
    "    print(f\"File {path.split('/')[-1]} caricato come {df.shape[1]} colonna unica.\")\n",
    "    return df\n",
    "\n",
    "# Esecuzione del caricamento corretto\n",
    "try:\n",
    "    df_train = load_as_single_string(TRAIN_FILE_PATH)\n",
    "    df_dev = load_as_single_string(DEV_FILE_PATH)\n",
    "    df_test = load_as_single_string(TEST_FILE_PATH)\n",
    "    \n",
    "    print(\"Caricamento Flessibile Completato.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Errore critico durante il caricamento: {e}\")\n",
    "    raise\n",
    "\n",
    "df_train.head(5).to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c4aab",
   "metadata": {},
   "source": [
    "### Pipeline di Parsing e Strutturazione dei Dati(Quadruple)\n",
    "Questa sezione implementa la pipeline di pre-elaborazione finale che trasforma la riga grezza di input in un formato Python strutturato, pronto per la Tokenizzazione del modello ModernBERT.\n",
    "\n",
    "Il codice esegue un processo a due fasi per ogni riga del dataset:\n",
    "\n",
    "1. **Separazione (Parsing della Riga Grezza)**: Esegue la divisione della riga unica *(full_line_data)* utilizzando il separatore Tab (\\t). Questo isola la recensione pulita *(review_text)* dalla stringa contenente le quadruple codificate (il target).\n",
    "\n",
    "2. **Decodifica Strutturale (Deep Parsing)**: Applica la funzione *parse_target_quadruples* alla stringa target. Questa funzione scompone la stringa in un dizionario con chiavi chiare **(span_A, span_B, category_aspect, sentiment)**, gestendo gli Indici Span Nullo (-1,-1) e validando la struttura a 4 elementi.\n",
    "\n",
    "L'output finale è il DataFrame pulito con la colonna parsed_quadruples, che contiene le informazioni di target necessarie per creare le label di Sequence Labeling nella fase successiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6000fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio della pipeline di parsing sui dataset...\n",
      "AVVISO: Il DataFrame è già stato processato (manca 'full_line_data'). Salto il parsing.\n",
      "AVVISO: Il DataFrame è già stato processato (manca 'full_line_data'). Salto il parsing.\n",
      "AVVISO: Il DataFrame è già stato processato (manca 'full_line_data'). Salto il parsing.\n",
      "Parsing completato su tutti i set (Train, Dev, Test).\n",
      "\n",
      "Anteprima del DataFrame di Training con le quadruple decodificate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>parsed_quadruples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace ##r wants $ 170 to just look at it then ad...</td>\n",
       "      <td>[{'span_A': (0, 2), 'span_B': (-1, -1), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update : i repaired it myself for $ 12 .</td>\n",
       "      <td>[{'span_A': (-1, -1), 'span_B': (-1, -1), 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i had nothing to lose since it was a paper wei...</td>\n",
       "      <td>[{'span_A': (-1, -1), 'span_B': (-1, -1), 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the shame of it is knowing it took me 15 minut...</td>\n",
       "      <td>[{'span_A': (18, 20), 'span_B': (-1, -1), 'cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first one that they shipped was obviously defe...</td>\n",
       "      <td>[{'span_A': (-1, -1), 'span_B': (7, 8), 'categ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  ace ##r wants $ 170 to just look at it then ad...   \n",
       "1           update : i repaired it myself for $ 12 .   \n",
       "2  i had nothing to lose since it was a paper wei...   \n",
       "3  the shame of it is knowing it took me 15 minut...   \n",
       "4  first one that they shipped was obviously defe...   \n",
       "\n",
       "                                   parsed_quadruples  \n",
       "0  [{'span_A': (0, 2), 'span_B': (-1, -1), 'categ...  \n",
       "1  [{'span_A': (-1, -1), 'span_B': (-1, -1), 'cat...  \n",
       "2  [{'span_A': (-1, -1), 'span_B': (-1, -1), 'cat...  \n",
       "3  [{'span_A': (18, 20), 'span_B': (-1, -1), 'cat...  \n",
       "4  [{'span_A': (-1, -1), 'span_B': (7, 8), 'categ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- I. DEFINIZIONE DELLE FUNZIONI DI PARSING ---\n",
    "\n",
    "def parse_target_quadruples(target_string):\n",
    "    \"\"\"\n",
    "    Decodifica la stringa di una singola quadrupla in un dizionario strutturato, \n",
    "    gestendo gli indici nulli (-1,-1).\n",
    "    \"\"\"\n",
    "    if not target_string:\n",
    "        return {} \n",
    "\n",
    "    parts = target_string.split()\n",
    "    \n",
    "    # La struttura corretta per la quadrupla è 4 elementi space-separated\n",
    "    if len(parts) != 4:\n",
    "        return {}\n",
    "    \n",
    "    # Assumiamo l'ordine: Span A, Aspect#Category, Sentiment, Span B\n",
    "    span_A_str, category_aspect, sentiment_str, span_B_str = parts\n",
    "\n",
    "    def parse_span(span_str):\n",
    "        \"\"\"Converte la stringa degli indici span (es. '1,2') in una tupla di interi.\"\"\"\n",
    "        if span_str == '-1,-1':\n",
    "            return (-1, -1)\n",
    "        try:\n",
    "            start, end = map(int, span_str.split(','))\n",
    "            return (start, end)\n",
    "        except ValueError:\n",
    "            return (-1, -1)\n",
    "\n",
    "    span_A = parse_span(span_A_str)\n",
    "    span_B = parse_span(span_B_str)\n",
    "    \n",
    "    try:\n",
    "        sentiment = int(sentiment_str)\n",
    "    except ValueError:\n",
    "        sentiment = -1 \n",
    "\n",
    "    return {\n",
    "        'span_A': span_A,\n",
    "        'span_B': span_B,\n",
    "        'category_aspect': category_aspect,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "\n",
    "\n",
    "def apply_deep_parsing(raw_quadruples_list):\n",
    "    \"\"\"Applica la funzione di deep parsing a tutti gli elementi di una lista di quadruple.\"\"\"\n",
    "    parsed_list = []\n",
    "    for raw_q in raw_quadruples_list:\n",
    "        parsed_list.append(parse_target_quadruples(raw_q))\n",
    "    return parsed_list\n",
    "\n",
    "\n",
    "def parse_full_line(full_line_string):\n",
    "    \"\"\"\n",
    "    Funzione principale: esegue lo split sul Tab ('\\\\t') e separa il testo dalle quadruple.\n",
    "    Gestisce anche le quadruple multiple.\n",
    "    \"\"\"\n",
    "    \n",
    "    parts = full_line_string.split('\\t', 1) \n",
    "    \n",
    "    if len(parts) != 2:\n",
    "        return full_line_string.strip(), []\n",
    "\n",
    "    review_text = parts[0].strip()\n",
    "    target_string_raw = parts[1].strip()\n",
    "    \n",
    "    target_string_clean = re.sub(r'[\\r\\n\\s]\\d+$', '', target_string_raw).strip()\n",
    "    \n",
    "    raw_quadruples_list = [q.strip() for q in target_string_clean.split('\\t') if q.strip()]\n",
    "\n",
    "    return review_text, raw_quadruples_list\n",
    "\n",
    "\n",
    "def apply_full_parsing_pipeline(df):\n",
    "    \"\"\"\n",
    "    Applica l'intera pipeline di parsing, rendendola IDEMPOTENTE:\n",
    "    esegue il parsing solo se la colonna sorgente 'full_line_data' è presente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- CONTROLLO DI SICUREZZA IDEMPOTENTE ---\n",
    "    if 'full_line_data' not in df.columns:\n",
    "        print(\"AVVISO: Il DataFrame è già stato processato (manca 'full_line_data'). Salto il parsing.\")\n",
    "        return df\n",
    "    # ------------------------------------------\n",
    "\n",
    "    df_copy = df.copy() \n",
    "    \n",
    "    # Passaggio 1: Split principale (Crea 'review_text' e 'raw_quadruples_list')\n",
    "    df_copy[['review_text', 'raw_quadruples_list']] = df_copy['full_line_data'].apply(\n",
    "        lambda x: pd.Series(parse_full_line(x))\n",
    "    )\n",
    "    df_copy = df_copy.drop(columns=['full_line_data'])\n",
    "    \n",
    "    # Passaggio 2: Parsing Approfondito (Crea 'parsed_quadruples')\n",
    "    df_copy['parsed_quadruples'] = df_copy['raw_quadruples_list'].apply(apply_deep_parsing)\n",
    "    \n",
    "    return df_copy.drop(columns=['raw_quadruples_list'])\n",
    "\n",
    "\n",
    "# --- II. ESECUZIONE SEQUENZIALE FINALE ---\n",
    "\n",
    "print(\"Avvio della pipeline di parsing sui dataset...\")\n",
    "\n",
    "# Esecuzione del Parsing (Ora è sicuro rieseguire questa cella!)\n",
    "df_train = apply_full_parsing_pipeline(df_train)\n",
    "df_dev = apply_full_parsing_pipeline(df_dev)\n",
    "df_test = apply_full_parsing_pipeline(df_test)\n",
    "\n",
    "print(\"Parsing completato su tutti i set (Train, Dev, Test).\")\n",
    "\n",
    "# Verifica finale\n",
    "print(\"\\nAnteprima del DataFrame di Training con le quadruple decodificate:\")\n",
    "display(df_train[['review_text', 'parsed_quadruples']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e2825",
   "metadata": {},
   "source": [
    "### Tokenizzazione e Allineamento delle Label\n",
    "Questo codice serve per convertire i dati dal formato strutturato di Pandas *(review_text e parsed_quadruples)* nel formato numerico accettato dal modello ModernBERT per l'addestramento.\n",
    "\n",
    "Il processo si svolge in tre passaggi chiave:\n",
    "\n",
    "1. **Tokenizzazione:** La recensione pulita *(review_text)* viene convertita in una sequenza di *Input IDs* (numeri) utilizzando il tokenizer di ModernBERT.\n",
    "\n",
    "2. **Allineamento degli Span:** Utilizziamo le funzioni integrate di Hugging Face per mappare gli Indici Span grezzi ((0, 2), etc.) agli indici dei nuovi subword tokens generati dal tokenizer. Questo passaggio risolve i problemi creati dai ## (tokenizzazione subword).\n",
    "\n",
    "3. **Sequence Labeling (Codifica BIO):** Sulla base degli indici allineati, creiamo l'array finale di Label Numeriche per ogni token della recensione (es. B-ASPECT, I-OPINION, O).\n",
    "\n",
    "Questo output (Input IDs e Label Sequence) è la forma finale del dataset, pronto per essere passato al Trainer di ModernBERT per il fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
