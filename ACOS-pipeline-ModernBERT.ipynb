{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6524ce4c",
   "metadata": {},
   "source": [
    "# ACOS-ABSA: Unified Preprocessing Pipeline for ModernBERT\n",
    "\n",
    "1. Il paper originale utilizza BERT-base-uncased (Devlin et al., 2018) come encoder principale. Sebbene rivoluzionario all'epoca, BERT ha un contesto limitato (512 token) e una capacità di generalizzazione inferiore rispetto ai modelli attuali.\n",
    "\n",
    "    * **La Nostra Soluzione:** Utilizziamo ModernBERT-base, un modello State-of-the-Art (2024) addestrato su un corpus molto più vasto e con una finestra di contesto estesa (8k token).\n",
    "\n",
    "    * **Vantaggio:** ModernBERT offre rappresentazioni contestuali più ricche, fondamentali per risolvere il problema degli Aspetti Impliciti (es. dedurre Price da \"it is expensive\"), che rappresentano una sfida critica nel dataset ACOS.\n",
    "+1\n",
    "\n",
    "2. Strategia di Allineamento Sub-word (Robust Tokenization)\n",
    "Il paper gestisce l'allineamento tra parole e token, ma spesso i modelli standard soffrono quando una parola annotata (es. \"difficulty\") viene spezzata in più sub-token (diffic, ##ulty).\n",
    "\n",
    "    * **La Nostra Soluzione:** Abbiamo implementato una pipeline di preprocessing personalizzata che utilizza i word_ids per mappare precisamente le etichette BIO sui sub-token.\n",
    "\n",
    "    * **Vantaggio:** Questo garantisce che nessun'informazione venga persa durante la tokenizzazione: se una parola è un'Opinione, tutti i suoi frammenti (token) erediteranno correttamente l'etichetta, migliorando la Recall del modello.\n",
    "\n",
    "3. Semplificazione Architetturale (Rimozione del CRF)\n",
    "Il modello Extract-Classify-ACOS impiega un layer CRF (Conditional Random Field) sopra BERT per \"pulire\" la sequenza di tag predetti e imporre vincoli logici.\n",
    "\n",
    "   * **La Nostra Soluzione:** Sfruttando la maggiore potenza di estrazione delle feature di ModernBERT, iniziamo con una Linear Classification Head standard.\n",
    "\n",
    "   * **Vantaggio:** Questo riduce drasticamente la complessità computazionale e i tempi di addestramento/inferenza. La capacità superiore di ModernBERT di apprendere le dipendenze locali rende spesso superfluo l'uso di un CRF, permettendo al modello di apprendere i vincoli BIO direttamente dai dati.\n",
    "\n",
    "4. Gestione \"Native\" degli Span Impliciti\n",
    "Come evidenziato nel paper, una larga percentuale di quadruple contiene aspetti o opinioni implicite (Span Nulli).\n",
    "\n",
    "    * **La Nostra Soluzione:** Il nostro preprocessing gestisce esplicitamente gli span (-1, -1) nel dataset, preparando il terreno per la fase successiva (Classificazione). Mentre la fase di estrazione corrente si concentra sugli span espliciti, i vettori [CLS] di ModernBERT sono già ottimizzati per catturare il contesto globale necessario a predire le categorie implicite nel secondo step della pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fc04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerie caricate.\n"
     ]
    }
   ],
   "source": [
    "# Import delle librerie necessarie\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "print(\"Librerie caricate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70bed1",
   "metadata": {},
   "source": [
    "### Impostazioni per la riproducibilità "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68aa33b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seeds impostati su 42.\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Imposto i seed per la riproducibilità.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        # Imposto anche i seed per la GPU, se disponibile\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# Esegui l'impostazione del seed\n",
    "set_seed(42) \n",
    "print(\"Random seeds impostati su 42.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c52222",
   "metadata": {},
   "source": [
    "### Configurazione Iniziale degli Hyperparameters (W&B)\n",
    "\n",
    "Questa sezione definisce i principali parametri di addestramento (*hyperparameters*) per il *fine-tuning* del modello **ModernBERT**, registrandoli in **Weights & Biases** per tracciabilità e riproducibilità.\n",
    "\n",
    "| Parametro | Valore | Motivazione della Scelta |\n",
    "| :--- | :--- | :--- |\n",
    "| **`learning_rate`** | `5e-5` (0.00005) | È il tasso di apprendimento *default* consigliato da Google/Hugging Face per il *fine-tuning* dei modelli BERT/RoBERTa. È un valore conservativo che assicura che il modello si adatti al nuovo *task* (ACOS) senza \"dimenticare\" le conoscenze acquisite nel *pre-training*. |\n",
    "| **`epochs`** | `5` | Un valore tipico e contenuto per il *fine-tuning* di modelli Transformer. Di solito, 3 o 4 *epochs* sono sufficienti per convergere, ma 5 offrono un buon equilibrio tra addestramento e prevenzione dell'overfitting sui dataset di dimensioni limitate come ACOS. |\n",
    "| **`batch_size`** | `16` | Questa dimensione del *batch* è comune quando si lavora con modelli grandi come RoBERTa-base, bilanciando la stabilità dell'addestramento con le limitazioni della **memoria GPU**. |\n",
    "| **`model_name`** | `answerdotai/ModernBERT-base` | Scegliamo questo modello specifico Encoder-only come \"ModernBERT\" per le prestazioni superiori e un pre-training più robusto rispetto al BERTbase originale |\n",
    "| **`dataset`** | `Laptop-ACOS` | Identifica il sotto-dataset specifico utilizzato per questo esperimento. |\n",
    "| **`seed`** | `42` | Il **seed di riproducibilità**, fissato a 42 (la convenzione standard ML), garantisce che ogni volta che lo *script* viene eseguito, l'inizializzazione dei pesi e lo *shuffling* dei dati siano identici, garantendo la tracciabilità scientifica dei risultati. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb63eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcristinatomaciello2001\u001b[0m (\u001b[33mcristinatextmining\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/cristinatomaciello/Desktop/Università/2anno/1semstre/big data/progetto-text-mining/wandb/run-20260214_164930-w86iot8t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/w86iot8t' target=\"_blank\">run_answerdotai/ModernBERT-base_Laptop-ACOS</a></strong> to <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/w86iot8t' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/w86iot8t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B inizializzato per il progetto: BigData-TextMining-ACOS\n"
     ]
    }
   ],
   "source": [
    "WANDB_ENTITY = \"cristinatextmining\"\n",
    "\n",
    "# 1. Definizione degli Hyperparameters\n",
    "config = {\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 16,\n",
    "    \"model_name\": \"answerdotai/ModernBERT-base\",\n",
    "    \"dataset\": \"Laptop-ACOS\",\n",
    "    \"seed\": 42,\n",
    "    'patience': 2  # Per Early Stopping\n",
    "}\n",
    "\n",
    "# 2. Inizializzazione del Run\n",
    "wandb.init(\n",
    "    project=\"BigData-TextMining-ACOS\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    config=config,\n",
    "    name=f\"run_{config['model_name']}_{config['dataset']}\"\n",
    ")\n",
    "\n",
    "print(f\"W&B inizializzato per il progetto: {wandb.run.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0ca9f",
   "metadata": {},
   "source": [
    "## Raw Data Parsing & Quadruple Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a0a15",
   "metadata": {},
   "source": [
    "### Caricamento dei 3 dataset LAPTOP-ACOS e dei 3 dataset RESTAURANT-ACOS\n",
    "Questa cella è dedicata al caricamento dei dataset TSV di ACOS (Training, Development e Test) dalla directory locale.\n",
    "\n",
    "Data la struttura complessa del file di annotazione, che contiene tabulazioni (\\t) interne e un numero variabile di quadruple per riga, la funzione load_as_single_string adotta una strategia di caricamento flessibile:\n",
    "\n",
    "1. **Forzatura Stringa Unica:** Viene utilizzato un separatore inesistente (\\x07) per istruire Pandas a caricare l'intera riga TSV come una singola colonna stringa *(full_line_data).*\n",
    "\n",
    "2. **Robustezza:** Questo approccio previene i comuni ParserError causati da tabulazioni o delimitatori sporchi interni, garantendo che i dati grezzi vengano letti completamente senza perdita.\n",
    "\n",
    "L'output di questa cella sono i tre DataFrame *(df_train, df_dev, df_test)*, ciascuno pronto per il parsing sequenziale sul contenuto della colonna full_line_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28042a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File laptop_train_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_dev_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File laptop_test_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_train_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_dev_quad_bert.tsv caricato come 1 colonna unica.\n",
      "File rest16_test_quad_bert.tsv caricato come 1 colonna unica.\n",
      "Caricamento Flessibile Completato.\n",
      "(2934, 1) (326, 1) (816, 1)\n",
      "(1530, 1) (171, 1) (583, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Definisci il percorso per ACOS\n",
    "DATA_DIR_ACOS = 'data/Laptop-ACOS/'\n",
    "\n",
    "# Definisci i percorsi completi dei file\n",
    "TRAIN_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_train_quad_bert.tsv')\n",
    "DEV_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_dev_quad_bert.tsv')\n",
    "TEST_FILE_PATH_ACOS = os.path.join(DATA_DIR_ACOS, 'laptop_test_quad_bert.tsv')\n",
    "\n",
    "# Definisci il percorso REESTAURANT\n",
    "DATA_DIR_RESTAURANT = 'data/Restaurant-ACOS/'\n",
    "\n",
    "# Definisci i percorsi completi dei file\n",
    "TRAIN_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_train_quad_bert.tsv')\n",
    "DEV_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_dev_quad_bert.tsv')\n",
    "TEST_FILE_PATH_RESTAURANT = os.path.join(DATA_DIR_RESTAURANT, 'rest16_test_quad_bert.tsv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_as_single_string(path):\n",
    "    \"\"\"\n",
    "    Carica l'intero file TSV in un'unica colonna stringa, forzando la lettura riga per riga, \n",
    "    per evitare errori di parsing dovuti a delimitatori interni.\n",
    "    \"\"\"\n",
    "    # 1. Utilizza read_csv ma forza l'uso di un separatore inesistente e non usare header\n",
    "    df = pd.read_csv(\n",
    "        path, \n",
    "        sep='\\x07', # Separa per un carattere inesistente (Bell character)\n",
    "        header=None, \n",
    "        on_bad_lines='skip', # Ignora le righe che danno problemi di formattazione\n",
    "        engine='python'\n",
    "    )\n",
    "    \n",
    "    # Rinomina l'unica colonna che contiene l'intera riga TSV\n",
    "    df.columns = ['full_line_data']    \n",
    "    print(f\"File {path.split('/')[-1]} caricato come {df.shape[1]} colonna unica.\")\n",
    "    return df\n",
    "\n",
    "# Esecuzione del caricamento corretto\n",
    "try:\n",
    "    df_train_laptop = load_as_single_string(TRAIN_FILE_PATH_ACOS)\n",
    "    df_dev_laptop = load_as_single_string(DEV_FILE_PATH_ACOS)\n",
    "    df_test_laptop = load_as_single_string(TEST_FILE_PATH_ACOS)\n",
    "    \n",
    "    df_train_rest = load_as_single_string(TRAIN_FILE_PATH_RESTAURANT)\n",
    "    df_dev_rest = load_as_single_string(DEV_FILE_PATH_RESTAURANT)\n",
    "    df_test_rest = load_as_single_string(TEST_FILE_PATH_RESTAURANT)\n",
    "    \n",
    "    print(\"Caricamento Flessibile Completato.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Errore critico durante il caricamento: {e}\")\n",
    "    raise\n",
    "\n",
    "print(df_train_laptop.shape, df_dev_laptop.shape, df_test_laptop.shape)\n",
    "print(df_train_rest.shape, df_dev_rest.shape, df_test_rest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c4aab",
   "metadata": {},
   "source": [
    "### Pipeline di Parsing e Strutturazione dei Dati(Quadruple)\n",
    "Questa sezione implementa la pipeline di pre-elaborazione finale che trasforma la riga grezza di input in un formato Python strutturato, pronto per la Tokenizzazione del modello ModernBERT.\n",
    "\n",
    "Il codice esegue un processo a due fasi per ogni riga del dataset:\n",
    "\n",
    "1. **Separazione (Parsing della Riga Grezza)**: Esegue la divisione della riga unica *(full_line_data)* utilizzando il separatore Tab (\\t). Questo isola la recensione pulita *(review_text)* dalla stringa contenente le quadruple codificate (il target).\n",
    "\n",
    "2. **Decodifica Strutturale (Deep Parsing)**: Applica la funzione *parse_target_quadruples* alla stringa target. Questa funzione scompone la stringa in un dizionario con chiavi chiare **(span_A, span_B, category_aspect, sentiment)**, gestendo gli Indici Span Nullo (-1,-1) e validando la struttura a 4 elementi.\n",
    "\n",
    "L'output finale è il DataFrame pulito con la colonna parsed_quadruples, che contiene le informazioni di target necessarie per creare le label di Sequence Labeling nella fase successiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6000fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creazione delle copie e avvio del parsing...\n",
      "Parsing completato con successo.\n",
      "\n",
      "Anteprima del DataFrame di Test (df_test_parsing_laptop):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>parsed_quadruples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the unit cost $ 275 to start with , so it is n...</td>\n",
       "      <td>[{'span_A': (1, 2), 'span_B': (12, 14), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going from ace ##r 15 to ace ##r 11 was diffic...</td>\n",
       "      <td>[{'span_A': (6, 9), 'span_B': (10, 11), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also it ' s not a true ss ##d drive in there b...</td>\n",
       "      <td>[{'span_A': (7, 10), 'span_B': (-1, -1), 'cate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the computer has difficulty switching between ...</td>\n",
       "      <td>[{'span_A': (1, 2), 'span_B': (3, 4), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 / 28 / 18 - a couple days ago i updated the ...</td>\n",
       "      <td>[{'span_A': (13, 15), 'span_B': (-1, -1), 'cat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  the unit cost $ 275 to start with , so it is n...   \n",
       "1  going from ace ##r 15 to ace ##r 11 was diffic...   \n",
       "2  also it ' s not a true ss ##d drive in there b...   \n",
       "3  the computer has difficulty switching between ...   \n",
       "4  2 / 28 / 18 - a couple days ago i updated the ...   \n",
       "\n",
       "                                   parsed_quadruples  \n",
       "0  [{'span_A': (1, 2), 'span_B': (12, 14), 'categ...  \n",
       "1  [{'span_A': (6, 9), 'span_B': (10, 11), 'categ...  \n",
       "2  [{'span_A': (7, 10), 'span_B': (-1, -1), 'cate...  \n",
       "3  [{'span_A': (1, 2), 'span_B': (3, 4), 'categor...  \n",
       "4  [{'span_A': (13, 15), 'span_B': (-1, -1), 'cat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anteprima del DataFrame di Test (df_test_parsing_rest):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>parsed_quadruples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yu ##m !</td>\n",
       "      <td>[{'span_A': (-1, -1), 'span_B': (0, 2), 'categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serves really good su ##shi .</td>\n",
       "      <td>[{'span_A': (3, 5), 'span_B': (2, 3), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the biggest portions but adequate .</td>\n",
       "      <td>[{'span_A': (3, 4), 'span_B': (0, 3), 'categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green tea cr ##eme br ##ule ##e is a must !</td>\n",
       "      <td>[{'span_A': (0, 7), 'span_B': (9, 10), 'catego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it has great su ##shi and even better service .</td>\n",
       "      <td>[{'span_A': (3, 5), 'span_B': (2, 3), 'categor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_text  \\\n",
       "0                                         yu ##m !   \n",
       "1                    serves really good su ##shi .   \n",
       "2          not the biggest portions but adequate .   \n",
       "3      green tea cr ##eme br ##ule ##e is a must !   \n",
       "4  it has great su ##shi and even better service .   \n",
       "\n",
       "                                   parsed_quadruples  \n",
       "0  [{'span_A': (-1, -1), 'span_B': (0, 2), 'categ...  \n",
       "1  [{'span_A': (3, 5), 'span_B': (2, 3), 'categor...  \n",
       "2  [{'span_A': (3, 4), 'span_B': (0, 3), 'categor...  \n",
       "3  [{'span_A': (0, 7), 'span_B': (9, 10), 'catego...  \n",
       "4  [{'span_A': (3, 5), 'span_B': (2, 3), 'categor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quadruple decodificate: [{'span_A': (0, 7), 'span_B': (9, 10), 'category_aspect': 'FOOD#QUALITY', 'sentiment': 2}]\n",
      "Testo corrispondente: green tea cr ##eme br ##ule ##e is a must !\n",
      "\n",
      "Dimensioni finali (Train, Dev, Test):\n",
      "(2934, 2) (326, 2) (816, 2)\n",
      "(1530, 2) (171, 2) (583, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- I. DEFINIZIONE DELLE FUNZIONI DI PARSING (Ottimizzate) ---\n",
    "\n",
    "def parse_target_quadruples(target_string):\n",
    "    \"\"\"\n",
    "    Decodifica la stringa di una singola quadrupla in un dizionario strutturato.\n",
    "    \"\"\"\n",
    "    if not target_string:\n",
    "        return {} \n",
    "\n",
    "    parts = target_string.split()\n",
    "    if len(parts) != 4:\n",
    "        return {}\n",
    "    \n",
    "    span_A_str, category_aspect, sentiment_str, span_B_str = parts\n",
    "\n",
    "    def parse_span(span_str):\n",
    "        if span_str == '-1,-1':\n",
    "            return (-1, -1)\n",
    "        try:\n",
    "            start, end = map(int, span_str.split(','))\n",
    "            return (start, end)\n",
    "        except ValueError:\n",
    "            return (-1, -1)\n",
    "\n",
    "    span_A = parse_span(span_A_str)\n",
    "    span_B = parse_span(span_B_str)\n",
    "    \n",
    "    try:\n",
    "        sentiment = int(sentiment_str)\n",
    "    except ValueError:\n",
    "        sentiment = -1 \n",
    "\n",
    "    return {\n",
    "        'span_A': span_A,\n",
    "        'span_B': span_B,\n",
    "        'category_aspect': category_aspect,\n",
    "        'sentiment': sentiment\n",
    "    }\n",
    "\n",
    "def apply_deep_parsing(raw_quadruples_list):\n",
    "    return [parse_target_quadruples(q) for q in raw_quadruples_list]\n",
    "\n",
    "def parse_full_line(full_line_string):\n",
    "    parts = full_line_string.split('\\t', 1) \n",
    "    if len(parts) != 2:\n",
    "        return full_line_string.strip(), []\n",
    "\n",
    "    review_text = parts[0].strip()\n",
    "    target_string_raw = parts[1].strip()\n",
    "    \n",
    "    # Pulizia residui numerici a fine riga\n",
    "    target_string_clean = re.sub(r'[\\r\\n\\s]\\d+$', '', target_string_raw).strip()\n",
    "    raw_quadruples_list = [q.strip() for q in target_string_clean.split('\\t') if q.strip()]\n",
    "\n",
    "    return review_text, raw_quadruples_list\n",
    "\n",
    "def apply_full_parsing_pipeline(df):\n",
    "    \"\"\"\n",
    "    Applica la pipeline di parsing restituendo un nuovo DataFrame processato.\n",
    "    \"\"\"\n",
    "    df_res = df.copy() \n",
    "    \n",
    "    # Passaggio 1: Split testo e liste di stringhe target\n",
    "    parsed_lines = df_res['full_line_data'].apply(parse_full_line)\n",
    "    df_res['review_text'] = parsed_lines.apply(lambda x: x[0])\n",
    "    df_res['raw_quadruples_list'] = parsed_lines.apply(lambda x: x[1])\n",
    "    \n",
    "    # Passaggio 2: Decodifica delle quadruple in dizionari\n",
    "    df_res['parsed_quadruples'] = df_res['raw_quadruples_list'].apply(apply_deep_parsing)\n",
    "    \n",
    "    # Pulizia colonne temporanee e originali\n",
    "    return df_res.drop(columns=['full_line_data', 'raw_quadruples_list'])\n",
    "\n",
    "\n",
    "# --- II. ESECUZIONE CON COPIA DEI DATASET ---\n",
    "\n",
    "print(\"Creazione delle copie e avvio del parsing...\")\n",
    "\n",
    "# 1. Creazione delle copie dedicate al parsing\n",
    "df_train_parsing_laptop = df_train_laptop.copy()\n",
    "df_dev_parsing_laptop = df_dev_laptop.copy()\n",
    "df_test_parsing_laptop = df_test_laptop.copy()\n",
    "\n",
    "df_train_parsing_rest = df_train_rest.copy()\n",
    "df_dev_parsing_rest = df_dev_rest.copy()\n",
    "df_test_parsing_rest = df_test_rest.copy()\n",
    "\n",
    "# 2. Applicazione della pipeline sulle nuove variabili\n",
    "df_train_parsing_laptop = apply_full_parsing_pipeline(df_train_parsing_laptop)\n",
    "df_dev_parsing_laptop = apply_full_parsing_pipeline(df_dev_parsing_laptop)\n",
    "df_test_parsing_laptop = apply_full_parsing_pipeline(df_test_parsing_laptop)\n",
    "\n",
    "df_train_parsing_rest = apply_full_parsing_pipeline(df_train_parsing_rest)\n",
    "df_dev_parsing_rest = apply_full_parsing_pipeline(df_dev_parsing_rest)\n",
    "df_test_parsing_rest = apply_full_parsing_pipeline(df_test_parsing_rest)\n",
    "\n",
    "print(\"Parsing completato con successo.\")\n",
    "\n",
    "# --- III. VERIFICA FINALE ---\n",
    "\n",
    "print(\"\\nAnteprima del DataFrame di Test (df_test_parsing_laptop):\")\n",
    "display(df_test_parsing_laptop[['review_text', 'parsed_quadruples']].head())\n",
    "\n",
    "print(\"\\nAnteprima del DataFrame di Test (df_test_parsing_rest):\")\n",
    "display(df_test_parsing_rest[['review_text', 'parsed_quadruples']].head())\n",
    "\n",
    "# Controllo specifico richiesto (riga 3)\n",
    "print(f\"\\nQuadruple decodificate: {df_test_parsing_rest['parsed_quadruples'].loc[3]}\")\n",
    "print(f\"Testo corrispondente: {df_test_parsing_rest['review_text'].loc[3]}\")\n",
    "\n",
    "print(\"\\nDimensioni finali (Train, Dev, Test):\")\n",
    "print(df_train_parsing_laptop.shape, df_dev_parsing_laptop.shape, df_test_parsing_laptop.shape)\n",
    "print(df_train_parsing_rest.shape, df_dev_parsing_rest.shape, df_test_parsing_rest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23c43c",
   "metadata": {},
   "source": [
    "## Sub-word Alignment & BIO Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e2825",
   "metadata": {},
   "source": [
    "### Tokenizzazione e Allineamento delle Label\n",
    "Questo codice serve per convertire i dati dal formato strutturato di Pandas *(review_text e parsed_quadruples)* nel formato numerico accettato dal modello ModernBERT per l'addestramento.\n",
    "\n",
    "Il processo si svolge in tre passaggi chiave:\n",
    "\n",
    "1. **Tokenizzazione:** La recensione pulita *(review_text)* viene convertita in una sequenza di *Input IDs* (numeri) utilizzando il tokenizer di ModernBERT.\n",
    "\n",
    "2. **Allineamento degli Span:** Utilizziamo le funzioni integrate di Hugging Face per mappare gli Indici Span grezzi ((0, 2), etc.) agli indici dei nuovi subword tokens generati dal tokenizer. Questo passaggio risolve i problemi creati dai ## (tokenizzazione subword).\n",
    "\n",
    "3. **Sequence Labeling (Codifica BIO):** Sulla base degli indici allineati, creiamo l'array finale di Label Numeriche per ogni token della recensione (es. B-ASPECT, I-OPINION, O).\n",
    "\n",
    "Questo output (Input IDs e Label Sequence) è la forma finale del dataset, pronto per essere passato al Trainer di ModernBERT per il fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff035dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allineamento in corso per lo split: TRAIN_LAPTOP...\n",
      "Allineamento in corso per lo split: DEV_LAPTOP...\n",
      "Allineamento in corso per lo split: TEST_LAPTOP...\n",
      "Allineamento in corso per lo split: TRAIN_RESTAURANT...\n",
      "Allineamento in corso per lo split: DEV_RESTAURANT...\n",
      "Allineamento in corso per lo split: TEST_RESTAURANT...\n",
      "\n",
      "==================================================\n",
      "VISUALIZZAZIONE DEI DATASET ALLINEATI\n",
      "\n",
      "--- PRIME RIGHE TRAIN LAPTOP---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace ##r wants $ 170 to just look at it then ad...</td>\n",
       "      <td>[50281, 584, 817, 83, 88, 1103, 5, 15046, 936,...</td>\n",
       "      <td>[0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>update : i repaired it myself for $ 12 .</td>\n",
       "      <td>[50281, 11183, 27, 74, 4762, 12260, 262, 17089...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i had nothing to lose since it was a paper wei...</td>\n",
       "      <td>[50281, 74, 10178, 26142, 936, 77, 583, 17480,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the shame of it is knowing it took me 15 minut...</td>\n",
       "      <td>[50281, 783, 1200, 482, 1171, 262, 261, 14428,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first one that they shipped was obviously defe...</td>\n",
       "      <td>[50281, 7053, 531, 3529, 9328, 1200, 6390, 423...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  ace ##r wants $ 170 to just look at it then ad...   \n",
       "1           update : i repaired it myself for $ 12 .   \n",
       "2  i had nothing to lose since it was a paper wei...   \n",
       "3  the shame of it is knowing it took me 15 minut...   \n",
       "4  first one that they shipped was obviously defe...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 584, 817, 83, 88, 1103, 5, 15046, 936,...   \n",
       "1  [50281, 11183, 27, 74, 4762, 12260, 262, 17089...   \n",
       "2  [50281, 74, 10178, 26142, 936, 77, 583, 17480,...   \n",
       "3  [50281, 783, 1200, 482, 1171, 262, 261, 14428,...   \n",
       "4  [50281, 7053, 531, 3529, 9328, 1200, 6390, 423...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE DEV LAPTOP ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this unit is ` ` pretty ` ` and st ##yl ##ish ...</td>\n",
       "      <td>[50281, 2520, 8522, 261, 65, 65, 38256, 65, 65...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for now i ' m okay with up ##ping the experien...</td>\n",
       "      <td>[50281, 1542, 2666, 74, 8, 78, 536, 333, 3113,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seems unlikely but whatever , i ' ll go with it .</td>\n",
       "      <td>[50281, 339, 3030, 328, 10355, 2858, 38499, 13...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this version has been my least favorite versio...</td>\n",
       "      <td>[50281, 2520, 4149, 7110, 20394, 2577, 38462, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 4, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- biggest disappointment is the track pad .</td>\n",
       "      <td>[50281, 14, 2760, 3219, 3431, 9626, 420, 261, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 0, 0, 1, 2, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  this unit is ` ` pretty ` ` and st ##yl ##ish ...   \n",
       "1  for now i ' m okay with up ##ping the experien...   \n",
       "2  seems unlikely but whatever , i ' ll go with it .   \n",
       "3  this version has been my least favorite versio...   \n",
       "4        - biggest disappointment is the track pad .   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 2520, 8522, 261, 65, 65, 38256, 65, 65...   \n",
       "1  [50281, 1542, 2666, 74, 8, 78, 536, 333, 3113,...   \n",
       "2  [50281, 339, 3030, 328, 10355, 2858, 38499, 13...   \n",
       "3  [50281, 2520, 4149, 7110, 20394, 2577, 38462, ...   \n",
       "4  [50281, 14, 2760, 3219, 3431, 9626, 420, 261, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 4, 4, 4, 4, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 3, 4, 4, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 3, 4, 4, 0, 0, 1, 2, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TEST LAPTOP ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the unit cost $ 275 to start with , so it is n...</td>\n",
       "      <td>[50281, 783, 8522, 16736, 5, 20450, 936, 5478,...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going from ace ##r 15 to ace ##r 11 was diffic...</td>\n",
       "      <td>[50281, 5681, 4064, 584, 817, 83, 1010, 936, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>also it ' s not a true ss ##d drive in there b...</td>\n",
       "      <td>[50281, 12563, 262, 8, 84, 1439, 66, 5672, 859...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the computer has difficulty switching between ...</td>\n",
       "      <td>[50281, 783, 32948, 7110, 38157, 90, 16065, 27...</td>\n",
       "      <td>[0, 0, 1, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 / 28 / 18 - a couple days ago i updated the ...</td>\n",
       "      <td>[50281, 19, 16, 1619, 16, 1093, 14, 66, 20313,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  the unit cost $ 275 to start with , so it is n...   \n",
       "1  going from ace ##r 15 to ace ##r 11 was diffic...   \n",
       "2  also it ' s not a true ss ##d drive in there b...   \n",
       "3  the computer has difficulty switching between ...   \n",
       "4  2 / 28 / 18 - a couple days ago i updated the ...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 783, 8522, 16736, 5, 20450, 936, 5478,...   \n",
       "1  [50281, 5681, 4064, 584, 817, 83, 1010, 936, 5...   \n",
       "2  [50281, 12563, 262, 8, 84, 1439, 66, 5672, 859...   \n",
       "3  [50281, 783, 32948, 7110, 38157, 90, 16065, 27...   \n",
       "4  [50281, 19, 16, 1619, 16, 1093, 14, 66, 20313,...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 3, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, ...  \n",
       "3  [0, 0, 1, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TRAIN RESTAURANT---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>judging from previous posts this used to be a ...</td>\n",
       "      <td>[50281, 6881, 3390, 4064, 35065, 28361, 2520, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we , there were four of us , arrived at noon -...</td>\n",
       "      <td>[50281, 664, 13, 9088, 12796, 12496, 1171, 316...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they never brought us compliment ##ary noodles...</td>\n",
       "      <td>[50281, 9328, 7594, 1288, 1224, 316, 21013, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the food was lou ##sy - too sweet or too salty...</td>\n",
       "      <td>[50281, 783, 19480, 4238, 77, 276, 817, 19089,...</td>\n",
       "      <td>[0, 0, 1, 0, 3, 4, 4, 4, 0, 3, 4, 0, 3, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after all that , they complained to me about t...</td>\n",
       "      <td>[50281, 6438, 455, 3529, 13, 9328, 21013, 1243...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  judging from previous posts this used to be a ...   \n",
       "1  we , there were four of us , arrived at noon -...   \n",
       "2  they never brought us compliment ##ary noodles...   \n",
       "3  the food was lou ##sy - too sweet or too salty...   \n",
       "4  after all that , they complained to me about t...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 6881, 3390, 4064, 35065, 28361, 2520, ...   \n",
       "1  [50281, 664, 13, 9088, 12796, 12496, 1171, 316...   \n",
       "2  [50281, 9328, 7594, 1288, 1224, 316, 21013, 20...   \n",
       "3  [50281, 783, 19480, 4238, 77, 276, 817, 19089,...   \n",
       "4  [50281, 6438, 455, 3529, 13, 9328, 21013, 1243...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 1, 0, 3, 4, 4, 4, 0, 3, 4, 0, 3, 4, 4, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE DEV RESTAURANT ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca n ' t wait wait for my next visit .</td>\n",
       "      <td>[50281, 6357, 79, 8, 85, 14061, 14061, 1542, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their sake list was extensive , but we were lo...</td>\n",
       "      <td>[50281, 14094, 84, 640, 3550, 4238, 2068, 3134...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the spicy tuna roll was unusually good and the...</td>\n",
       "      <td>[50281, 783, 1033, 2576, 85, 9821, 1811, 4238,...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 3, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we love th pink pony .</td>\n",
       "      <td>[50281, 664, 26617, 394, 49723, 81, 2421, 15, ...</td>\n",
       "      <td>[0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this place has got to be the best japanese res...</td>\n",
       "      <td>[50281, 2520, 5070, 7110, 19559, 936, 1257, 78...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0             ca n ' t wait wait for my next visit .   \n",
       "1  their sake list was extensive , but we were lo...   \n",
       "2  the spicy tuna roll was unusually good and the...   \n",
       "3                             we love th pink pony .   \n",
       "4  this place has got to be the best japanese res...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 6357, 79, 8, 85, 14061, 14061, 1542, 2...   \n",
       "1  [50281, 14094, 84, 640, 3550, 4238, 2068, 3134...   \n",
       "2  [50281, 783, 1033, 2576, 85, 9821, 1811, 4238,...   \n",
       "3  [50281, 664, 26617, 394, 49723, 81, 2421, 15, ...   \n",
       "4  [50281, 2520, 5070, 7110, 19559, 936, 1257, 78...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 1, 2, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 3, 0, 0, 1, 2, ...  \n",
       "3  [0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIME RIGHE TEST RESTAURANT ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yu ##m !</td>\n",
       "      <td>[50281, 30838, 817, 78, 2, 50282, 50283, 50283...</td>\n",
       "      <td>[0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serves really good su ##shi .</td>\n",
       "      <td>[50281, 1498, 265, 28235, 12311, 3467, 817, 41...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not the biggest portions but adequate .</td>\n",
       "      <td>[50281, 1439, 783, 2760, 3219, 631, 621, 2858,...</td>\n",
       "      <td>[0, 3, 4, 4, 4, 1, 2, 0, 3, 4, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green tea cr ##eme br ##ule ##e is a must !</td>\n",
       "      <td>[50281, 11707, 442, 66, 7083, 817, 20867, 1288...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it has great su ##shi and even better service .</td>\n",
       "      <td>[50281, 262, 7110, 17124, 3467, 817, 41386, 39...</td>\n",
       "      <td>[0, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_text  \\\n",
       "0                                         yu ##m !   \n",
       "1                    serves really good su ##shi .   \n",
       "2          not the biggest portions but adequate .   \n",
       "3      green tea cr ##eme br ##ule ##e is a must !   \n",
       "4  it has great su ##shi and even better service .   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [50281, 30838, 817, 78, 2, 50282, 50283, 50283...   \n",
       "1  [50281, 1498, 265, 28235, 12311, 3467, 817, 41...   \n",
       "2  [50281, 1439, 783, 2760, 3219, 631, 621, 2858,...   \n",
       "3  [50281, 11707, 442, 66, 7083, 817, 20867, 1288...   \n",
       "4  [50281, 262, 7110, 17124, 3467, 817, 41386, 39...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 3, 4, 4, 4, 1, 2, 0, 3, 4, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, ...  \n",
       "4  [0, 0, 0, 3, 1, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Caricamento del Tokenizer di ModernBERT\n",
    "tokenizer_name = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def encode_and_align_labels(words, parsed_quadruples, tokenizer, max_len=128):\n",
    "    \"\"\"\n",
    "    Tokenizza il testo e allinea gli span BIO in modo che solo il primo token \n",
    "    di uno span sia 'B-' e i successivi siano 'I-'.\n",
    "    \"\"\"\n",
    "    tokenized_input = tokenizer(\n",
    "        words,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = [\"O\"] * max_len\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    \n",
    "    for quad in parsed_quadruples:\n",
    "        # Estraiamo gli span per Aspect (A) e Opinion (B)\n",
    "        asp_span = quad.get('span_A', (-1, -1))\n",
    "        opi_span = quad.get('span_B', (-1, -1))\n",
    "        \n",
    "        # Funzione di utilità per allineare uno span specifico\n",
    "        def align_span(span, b_tag, i_tag):\n",
    "            if span == (-1, -1):\n",
    "                return\n",
    "            \n",
    "            start_word_idx, end_word_idx = span\n",
    "            span_started = False # Flag per gestire il passaggio da B a I\n",
    "            \n",
    "            for i, word_id in enumerate(word_ids):\n",
    "                if i >= max_len or word_id is None:\n",
    "                    continue\n",
    "                \n",
    "                # Se il token appartiene a una parola compresa nello span [start, end)\n",
    "                if start_word_idx <= word_id < end_word_idx:\n",
    "                    if not span_started:\n",
    "                        labels[i] = b_tag\n",
    "                        span_started = True\n",
    "                    else:\n",
    "                        labels[i] = i_tag\n",
    "\n",
    "        # Applichiamo la logica a entrambi gli span\n",
    "        align_span(asp_span, \"B-ASP\", \"I-ASP\")\n",
    "        align_span(opi_span, \"B-OPI\", \"I-OPI\")\n",
    "\n",
    "    # Mappatura in ID numerici\n",
    "    label_map = {\"O\": 0, \"B-ASP\": 1, \"I-ASP\": 2, \"B-OPI\": 3, \"I-OPI\": 4}\n",
    "    label_ids = [label_map[l] for l in labels]\n",
    "\n",
    "    return {\n",
    "        'input_ids': tokenized_input['input_ids'],\n",
    "        'attention_mask': tokenized_input['attention_mask'],\n",
    "        'labels': label_ids\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "def process_align_dataset(df, tokenizer, split_name):\n",
    "    \"\"\"\n",
    "    Applica l'allineamento e aggiunge le colonne input_ids, attention_mask e labels.\n",
    "    \"\"\"\n",
    "    print(f\"Allineamento in corso per lo split: {split_name}...\")\n",
    "    \n",
    "    # Applichiamo la funzione riga per riga\n",
    "    # Usiamo .split() perché il testo è pre-tokenizzato nel dataset originale\n",
    "    processed_series = df.apply(\n",
    "        lambda row: encode_and_align_labels(\n",
    "            row['review_text'].split(), \n",
    "            row['parsed_quadruples'], \n",
    "            tokenizer, \n",
    "            max_len=128\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Convertiamo la lista di dizionari in un DataFrame e lo concateniamo\n",
    "    df_result = pd.DataFrame(processed_series.tolist(), index=df.index)\n",
    "    return pd.concat([df, df_result], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. CREAZIONE DELLE COPIE DEI DATASET ---\n",
    "# Creiamo copie profonde per evitare di modificare i DataFrame originali\n",
    "df_train_align_laptop = df_train_parsing_laptop.copy()\n",
    "df_dev_align_laptop = df_dev_parsing_laptop.copy()\n",
    "df_test_align_laptop = df_test_parsing_laptop.copy()\n",
    "\n",
    "df_train_align_rest = df_train_parsing_rest.copy()\n",
    "df_dev_align_rest = df_dev_parsing_rest.copy()\n",
    "df_test_align_rest = df_test_parsing_rest.copy()\n",
    "\n",
    "# --- 2. ESECUZIONE DELL'ALLINEAMENTO ---\n",
    "df_train_align_laptop = process_align_dataset(df_train_align_laptop, tokenizer, \"TRAIN_LAPTOP\")\n",
    "df_dev_align_laptop = process_align_dataset(df_dev_align_laptop, tokenizer, \"DEV_LAPTOP\")\n",
    "df_test_align_laptop = process_align_dataset(df_test_align_laptop, tokenizer, \"TEST_LAPTOP\")\n",
    "\n",
    "df_train_align_rest = process_align_dataset(df_train_align_rest, tokenizer, \"TRAIN_RESTAURANT\")\n",
    "df_dev_align_rest = process_align_dataset(df_dev_align_rest, tokenizer, \"DEV_RESTAURANT\")\n",
    "df_test_align_rest = process_align_dataset(df_test_align_rest, tokenizer, \"TEST_RESTAURANT\")\n",
    "\n",
    "# --- 3. OUTPUT DELLE PRIME RIGHE ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VISUALIZZAZIONE DEI DATASET ALLINEATI\")\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TRAIN LAPTOP---\")\n",
    "display(df_train_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE DEV LAPTOP ---\")\n",
    "display(df_dev_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TEST LAPTOP ---\")\n",
    "display(df_test_align_laptop[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TRAIN RESTAURANT---\")\n",
    "display(df_train_align_rest[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE DEV RESTAURANT ---\")\n",
    "display(df_dev_align_rest[['review_text', 'input_ids', 'labels']].head())\n",
    "\n",
    "print(\"\\n--- PRIME RIGHE TEST RESTAURANT ---\")\n",
    "display(df_test_align_rest[['review_text', 'input_ids', 'labels']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84319964",
   "metadata": {},
   "source": [
    "## PyTorch Dataset & DataLoader Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114bba6",
   "metadata": {},
   "source": [
    "### Creazione di PyTorch Dataset e DataLoader\n",
    "In questa fase, trasformiamo i nostri DataFrame Pandas (strutture dati tabellari) in oggetti Dataset e DataLoader di PyTorch. Questo passaggio è il \"ponte\" necessario per alimentare il modello ModernBERT durante l'addestramento.\n",
    "\n",
    "#### Obiettivi di questa sezione:\n",
    "\n",
    "  1. Standardizzazione dei Dati (ACOSDataset):\n",
    "\n",
    "       * I modelli basati su Transformer non possono leggere direttamente i DataFrame. La classe ACOSDataset estrae le liste di input_ids, attention_mask e labels e le converte in Tensori PyTorch (torch.tensor).\n",
    "\n",
    "       * Viene utilizzato il tipo di dato torch.long, richiesto dai layer di embedding e dalle funzioni di calcolo della Loss per task di classificazione.\n",
    "\n",
    "  2. Gestione del Caricamento (DataLoader):\n",
    "\n",
    "      * Batching: Invece di caricare l'intero dataset in memoria (rischioso per la GPU), i dati vengono divisi in piccoli blocchi chiamati Batch (nel nostro caso di dimensione 16).\n",
    "\n",
    "      * Shuffling (Solo Training): Utilizziamo shuffle=True nel train_loader per rimescolare l'ordine delle frasi a ogni epoca. Questo impedisce al modello di imparare l'ordine sequenziale dei dati, costringendolo invece a focalizzarsi sui pattern linguistici reali.\n",
    "\n",
    "      * Efficienza: I DataLoader gestiscono il caricamento dei dati in parallelo, ottimizzando i tempi di addestramento sulla GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7f7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset e DataLoaders creati con successo!\n",
      "Esempi nel set di Training LAPTOP: 2934\n",
      "Esempi nel set di Training RESTAURANT: 1530\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ACOSDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Estraiamo le colonne che abbiamo generato nella fase di allineamento\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.labels = df['labels'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convertiamo le liste in Tensori di PyTorch (LongTensor per ID e Label)\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- CREAZIONE DELLE ISTANZE ---\n",
    "\n",
    "# Creiamo i dataset per il dominio Laptop\n",
    "train_dataset_laptop = ACOSDataset(df_train_align_laptop)\n",
    "dev_dataset_laptop = ACOSDataset(df_dev_align_laptop)\n",
    "test_dataset_laptop = ACOSDataset(df_test_align_laptop)\n",
    "\n",
    "# Creiamo i dataset per il dominio restaruant\n",
    "train_dataset_rest = ACOSDataset(df_train_align_rest)\n",
    "dev_dataset_rest = ACOSDataset(df_dev_align_rest)\n",
    "test_dataset_rest = ACOSDataset(df_test_align_rest)\n",
    "\n",
    "# --- CONFIGURAZIONE DATALOADERS ---\n",
    "\n",
    "BATCH_SIZE = 16 # Numero di frasi analizzate contemporaneamente\n",
    "\n",
    "train_loader_laptop = DataLoader(train_dataset_laptop, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader_laptop = DataLoader(dev_dataset_laptop, batch_size=BATCH_SIZE)\n",
    "test_loader_laptop = DataLoader(test_dataset_laptop, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_loader_rest = DataLoader(train_dataset_rest, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader_rest = DataLoader(dev_dataset_rest, batch_size=BATCH_SIZE)\n",
    "test_loader_rest = DataLoader(test_dataset_rest, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Dataset e DataLoaders creati con successo!\")\n",
    "print(f\"Esempi nel set di Training LAPTOP: {len(train_dataset_laptop)}\")\n",
    "print(f\"Esempi nel set di Training RESTAURANT: {len(train_dataset_rest)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b70053",
   "metadata": {},
   "source": [
    "### Definizione e l'Inizializzazione del Modello di Token Classification.\n",
    "\n",
    "1. Caricare il \"Cervello\" (ModernBERT Pre-trained)\n",
    "Dobbiamo scaricare il modello ModernBERT-base dal repository di Hugging Face. In questa fase, il modello sa già \"leggere\" e \"capire\" la lingua inglese perché è stato addestrato su miliardi di testi, ma non sa ancora nulla del tuo task specifico (ACOS). È come un laureato in lingue che però non ha mai lavorato in un ristorante o in un negozio di computer.\n",
    "\n",
    "2. Aggiungere la \"Testa\" di Classificazione\n",
    "ModernBERT normalmente restituisce dei vettori numerici (embedding) per ogni parola. Noi dobbiamo aggiungere sopra questi vettori uno strato finale chiamato Linear Layer (o testa di classificazione).\n",
    "\n",
    "   * Questo strato prenderà l'output di ModernBERT e lo \"schiaccerà\" su 5 classi possibili: 0 (O), 1 (B-ASP), 2 (I-ASP), 3 (B-OPI), 4 (I-OPI).\n",
    "\n",
    "   * Il modello dovrà imparare a mappare ogni pezzetto di frase a una di queste cinque etichette.\n",
    "\n",
    "3. Configurare la Strategia di Apprendimento (Optimizer & Loss)\n",
    "Dobbiamo dare al modello gli strumenti per imparare dai suoi errori:\n",
    "\n",
    "  * Loss Function (Funzione di Perdita): Useremo la CrossEntropyLoss. È il \"voto\" che diamo al modello. Se il modello dice che \"pizza\" è un'opinione (B-OPI) ma il tuo dataset dice che è un aspetto (B-ASP), la Loss sarà alta. Il modello cercherà di abbassarla il più possibile.\n",
    "\n",
    "   * Optimizer (Ottimizzatore): Di solito si usa AdamW. È l'algoritmo che decide \"come\" e \"quanto\" cambiare i pesi interni del modello per correggere gli errori.\n",
    "\n",
    "   * Learning Rate: La velocità con cui il modello impara. Se è troppo alta, il modello è \"frettoloso\" e sbaglia; se è troppo bassa, non imparerà mai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "404429b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acceleratore Apple Metal (MPS) Trovato\n",
      "Scaricamento e configurazione di ModernBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dbc5d264ec4da7ac035b21a0abda97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mModernBertForTokenClassification LOAD REPORT\u001b[0m from: answerdotai/ModernBERT-base\n",
      "Key               | Status     | \n",
      "------------------+------------+-\n",
      "decoder.bias      | UNEXPECTED | \n",
      "classifier.bias   | MISSING    | \n",
      "classifier.weight | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODELLO PRONTO PER IL TRAINING\n",
      "==================================================\n",
      "Architettura: ModernBERT-base\n",
      "Task: Token Classification (Estrazione Aspetti & Opinioni)\n",
      "Numero di Classi: 5\n",
      "Optimizer: AdamW (lr=5e-5)\n",
      "Loss Function: CrossEntropyLoss\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- 1. CONFIGURAZIONE DEL DEVICE ---\n",
    "# Se hai una GPU NVIDIA, userà 'cuda'. Se hai un Mac M1/M2, userà 'mps'. Altrimenti 'cpu'.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\" GPU Trovata: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\" Acceleratore Apple Metal (MPS) Trovato\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\" Nessuna GPU trovata. L'addestramento sarà lento.\")\n",
    "\n",
    "# --- 2. CARICAMENTO DI MODERNBERT (IL \"CERVELLO\") + TESTA DI CLASSIFICAZIONE ---\n",
    "# Definiamo le 5 etichette: 0=O, 1=B-ASP, 2=I-ASP, 3=B-OPI, 4=I-OPI\n",
    "NUM_LABELS = 5 \n",
    "\n",
    "print(\"Scaricamento e configurazione di ModernBERT...\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "# Spostiamo il modello sul dispositivo di calcolo (GPU/MPS/CPU)\n",
    "model.to(device)\n",
    "\n",
    "# --- 3. CONFIGURAZIONE DELL'OTTIMIZZATORE E DELLA LOSS ---\n",
    "\n",
    "# A. Optimizer (AdamW)\n",
    "# Usiamo il Learning Rate standard di 5e-5 come definito nei parametri sperimentali \n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# B. Loss Function (CrossEntropyLoss)\n",
    "# La funzione che calcola l'errore tra la predizione del modello e le label reali.\n",
    "# Nota: 'ignore_index=-100' è lo standard di PyTorch per ignorare i token di padding nel calcolo dell'errore.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODELLO PRONTO PER IL TRAINING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Architettura: ModernBERT-base\")\n",
    "print(f\"Task: Token Classification (Estrazione Aspetti & Opinioni)\")\n",
    "print(f\"Numero di Classi: {NUM_LABELS}\")\n",
    "print(f\"Optimizer: AdamW (lr=5e-5)\")\n",
    "print(f\"Loss Function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c723566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Inizio Training su LAPTOP: 5 epoche su mps\n",
      "🛑 Early Stopping configurato con Patience = 2\n",
      "\n",
      "--- Epoca 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 1: 100%|██████████| 184/184 [1:01:52<00:00, 20.17s/it, loss=0.0488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Train Loss: 0.0710 | 🔍 Valid Loss: 0.0343\n",
      "💾 Miglior modello trovato (Loss: 0.0343)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c38c6349e4bdca28644d962b3718d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 2: 100%|██████████| 184/184 [57:56<00:00, 18.89s/it, loss=0.0479] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Train Loss: 0.0280 | 🔍 Valid Loss: 0.0311\n",
      "💾 Miglior modello trovato (Loss: 0.0311)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd47a23c7da480ca72633f41b5b2954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 3: 100%|██████████| 184/184 [1:13:39<00:00, 24.02s/it, loss=0.00788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Train Loss: 0.0178 | 🔍 Valid Loss: 0.0284\n",
      "💾 Miglior modello trovato (Loss: 0.0284)! Salvataggio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3affc35bbdca40f298c3d038c37a5e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoca 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 4: 100%|██████████| 184/184 [1:08:28<00:00, 22.33s/it, loss=0.00218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Train Loss: 0.0098 | 🔍 Valid Loss: 0.0330\n",
      "⚠️ Nessun miglioramento. Patience: 1/2\n",
      "\n",
      "--- Epoca 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 5: 100%|██████████| 184/184 [1:19:17<00:00, 25.86s/it, loss=0.0117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Train Loss: 0.0048 | 🔍 Valid Loss: 0.0340\n",
      "⚠️ Nessun miglioramento. Patience: 2/2\n",
      "\n",
      "🛑 EARLY STOPPING ATTIVATO! Interruzione all'epoca 5.\n",
      "\n",
      "✅ Fine Addestramento.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█▅▅▄▂▃▂▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▃▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁</td></tr><tr><td>valid_loss_epoch</td><td>█▄▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.01166</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train_loss_epoch</td><td>0.00477</td></tr><tr><td>valid_loss_epoch</td><td>0.03401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_answerdotai/ModernBERT-base_Laptop-ACOS</strong> at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/w86iot8t' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS/runs/w86iot8t</a><br> View project at: <a href='https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS' target=\"_blank\">https://wandb.ai/cristinatextmining/BigData-TextMining-ACOS</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260214_164930-w86iot8t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import wandb # Assumo che tu abbia già importato wandb\n",
    "\n",
    "# --- CONFIGURAZIONE EARLY STOPPING ---\n",
    "# Impostiamo la pazienza: quante epoche aspettare senza miglioramenti?\n",
    "patience = config.get('patience', 2)  # Prende da config o usa 3 come default\n",
    "patience_counter = 0                  # Contatore inizializzato a 0\n",
    "\n",
    "# L'ottimizzatore prende il learning rate dalla tua variabile 'config'\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=config['learning_rate'] \n",
    ")\n",
    "\n",
    "# Scheduler: Riduce il learning rate linearmente\n",
    "total_steps = len(train_loader_laptop) * config['epochs']\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# --- 2. FUNZIONI DI SUPPORTO ---\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            total_loss += outputs.loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device, epoch_idx):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        # A. Dati su GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # B. Reset e Calcoli\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # C. Aggiornamento Pesi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Log istantaneo su W&B (opzionale, per non intasare i grafici)\n",
    "        wandb.log({\"batch_loss\": loss.item()})\n",
    "        \n",
    "        loop.set_description(f\"Epoca {epoch_idx + 1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# --- 3. CICLO DI ADDESTRAMENTO (LOOP) ---\n",
    "\n",
    "print(f\"🚀 Inizio Training su LAPTOP: {config['epochs']} epoche su {device}\")\n",
    "print(f\"🛑 Early Stopping configurato con Patience = {patience}\")\n",
    "\n",
    "best_valid_loss_laptop = float('inf')\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\n--- Epoca {epoch+1}/{config['epochs']} ---\")\n",
    "    \n",
    "    # 1. Training\n",
    "    train_loss_laptop = train_epoch(model, train_loader_laptop, optimizer, scheduler, device, epoch)\n",
    "    \n",
    "    # 2. Validazione\n",
    "    valid_loss_laptop = evaluate_model(model, dev_loader_laptop, device)\n",
    "    \n",
    "    print(f\"📉 Train Loss: {train_loss_laptop:.4f} | 🔍 Valid Loss: {valid_loss_laptop:.4f}\")\n",
    "    \n",
    "    # 3. Log metriche epoca su W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss_epoch\": train_loss_laptop,\n",
    "        \"valid_loss_epoch\": valid_loss_laptop\n",
    "    })\n",
    "    \n",
    "    # --- LOGICA EARLY STOPPING & CHECKPOINT ---\n",
    "    \n",
    "    # Se il modello migliora (la valid loss scende)\n",
    "    if valid_loss_laptop < best_valid_loss_laptop:\n",
    "        best_valid_loss_laptop = valid_loss_laptop\n",
    "        patience_counter = 0  # ### NUOVO: Resettiamo la pazienza ###\n",
    "        \n",
    "        print(f\"💾 Miglior modello trovato (Loss: {best_valid_loss_laptop:.4f})! Salvataggio...\")\n",
    "        \n",
    "        # Creiamo la cartella se non esiste (sicurezza aggiuntiva)\n",
    "        import os\n",
    "        if not os.path.exists(\"./best_model_laptop\"):\n",
    "            os.makedirs(\"./best_model_laptop\")\n",
    "            \n",
    "        model.save_pretrained(\"./best_model_laptop\")\n",
    "        \n",
    "    # Se il modello NON migliora\n",
    "    else:\n",
    "        patience_counter += 1  # ### NUOVO: Incrementiamo il contatore ###\n",
    "        print(f\"⚠️ Nessun miglioramento. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        # Se abbiamo esaurito la pazienza\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n🛑 EARLY STOPPING ATTIVATO! Interruzione all'epoca {epoch+1}.\")\n",
    "            break # Esce dal ciclo for\n",
    "\n",
    "print(\"\\n✅ Fine Addestramento.\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvTextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
